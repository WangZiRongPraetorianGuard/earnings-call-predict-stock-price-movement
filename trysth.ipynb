{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6147c7bf-bff2-49c1-b160-e2c5e5da16c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_symbol</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>1_day_change_rate</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TTWO</td>\n",
       "      <td>Take-Two Interactive Software (TTWO) Q4 2024 E...</td>\n",
       "      <td>2024-05-16</td>\n",
       "      <td>p.m. ET\\r\\n\\r\\nOperator\\r\\n\\r\\nGreetings and ...</td>\n",
       "      <td>0.012048</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMAT</td>\n",
       "      <td>Applied Materials (AMAT) Q2 2024 Earnings Call...</td>\n",
       "      <td>2024-05-16</td>\n",
       "      <td>perator\\r\\n\\r\\nWelcome to the Applied Material...</td>\n",
       "      <td>-0.009111</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DXC</td>\n",
       "      <td>DXC Technology (DXC) Q4 2024 Earnings Call Tra...</td>\n",
       "      <td>2024-05-16</td>\n",
       "      <td>ator\\r\\n\\r\\nHello, and welcome to the DXC Tech...</td>\n",
       "      <td>-0.169014</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LSPD</td>\n",
       "      <td>Lightspeed Commerce (LSPD) Q4 2024 Earnings Ca...</td>\n",
       "      <td>2024-05-16</td>\n",
       "      <td>Operator\\r\\n\\r\\nThank you for standing by, and...</td>\n",
       "      <td>0.021192</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JD</td>\n",
       "      <td>JD.com (JD) Q1 2024 Earnings Call Transcript</td>\n",
       "      <td>2024-05-16</td>\n",
       "      <td>, and thank you for standing by for JD.com's f...</td>\n",
       "      <td>0.029180</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>PYCR</td>\n",
       "      <td>Paycor HCM (PYCR) Q1 2024 Earnings Call Transc...</td>\n",
       "      <td>2023-11-08</td>\n",
       "      <td>r\\r\\n\\r\\nLadies and gentlemen, thank you for s...</td>\n",
       "      <td>0.044258</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>DUOL</td>\n",
       "      <td>Duolingo (DUOL) Q3 2023 Earnings Call Transcript</td>\n",
       "      <td>2023-11-08</td>\n",
       "      <td>van\\r\\n\\r\\nGood evening, everyone. If you have...</td>\n",
       "      <td>0.213726</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>AFRM</td>\n",
       "      <td>Affirm (AFRM) Q1 2024 Earnings Call Transcript</td>\n",
       "      <td>2023-11-08</td>\n",
       "      <td>d afternoon, ladies and gentlemen. Thank you f...</td>\n",
       "      <td>0.142463</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>CART</td>\n",
       "      <td>Instacart (CART) Q3 2023 Earnings Call Transcript</td>\n",
       "      <td>2023-11-08</td>\n",
       "      <td>Good day and thank you for standing by. Welcom...</td>\n",
       "      <td>-0.101322</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>TTWO</td>\n",
       "      <td>Take-Two Interactive Software (TTWO) Q2 2024 E...</td>\n",
       "      <td>2023-11-08</td>\n",
       "      <td>p.m. ET\\r\\n\\r\\nOperator\\r\\n\\r\\nGreetings, and...</td>\n",
       "      <td>0.019865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>985 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    stock_symbol                                              title  \\\n",
       "0           TTWO  Take-Two Interactive Software (TTWO) Q4 2024 E...   \n",
       "1           AMAT  Applied Materials (AMAT) Q2 2024 Earnings Call...   \n",
       "2            DXC  DXC Technology (DXC) Q4 2024 Earnings Call Tra...   \n",
       "3           LSPD  Lightspeed Commerce (LSPD) Q4 2024 Earnings Ca...   \n",
       "4             JD       JD.com (JD) Q1 2024 Earnings Call Transcript   \n",
       "..           ...                                                ...   \n",
       "980         PYCR  Paycor HCM (PYCR) Q1 2024 Earnings Call Transc...   \n",
       "981         DUOL   Duolingo (DUOL) Q3 2023 Earnings Call Transcript   \n",
       "982         AFRM     Affirm (AFRM) Q1 2024 Earnings Call Transcript   \n",
       "983         CART  Instacart (CART) Q3 2023 Earnings Call Transcript   \n",
       "984         TTWO  Take-Two Interactive Software (TTWO) Q2 2024 E...   \n",
       "\n",
       "           date                                         paragraphs  \\\n",
       "0    2024-05-16   p.m. ET\\r\\n\\r\\nOperator\\r\\n\\r\\nGreetings and ...   \n",
       "1    2024-05-16  perator\\r\\n\\r\\nWelcome to the Applied Material...   \n",
       "2    2024-05-16  ator\\r\\n\\r\\nHello, and welcome to the DXC Tech...   \n",
       "3    2024-05-16  Operator\\r\\n\\r\\nThank you for standing by, and...   \n",
       "4    2024-05-16  , and thank you for standing by for JD.com's f...   \n",
       "..          ...                                                ...   \n",
       "980  2023-11-08  r\\r\\n\\r\\nLadies and gentlemen, thank you for s...   \n",
       "981  2023-11-08  van\\r\\n\\r\\nGood evening, everyone. If you have...   \n",
       "982  2023-11-08  d afternoon, ladies and gentlemen. Thank you f...   \n",
       "983  2023-11-08  Good day and thank you for standing by. Welcom...   \n",
       "984  2023-11-08   p.m. ET\\r\\n\\r\\nOperator\\r\\n\\r\\nGreetings, and...   \n",
       "\n",
       "     1_day_change_rate  label  \n",
       "0             0.012048      1  \n",
       "1            -0.009111     -1  \n",
       "2            -0.169014     -1  \n",
       "3             0.021192      1  \n",
       "4             0.029180      1  \n",
       "..                 ...    ...  \n",
       "980           0.044258      1  \n",
       "981           0.213726      1  \n",
       "982           0.142463      1  \n",
       "983          -0.101322     -1  \n",
       "984           0.019865      1  \n",
       "\n",
       "[985 rows x 6 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('0522_price_volatility_binary_label.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31bb616c-727e-42e5-90cc-7000c51d9fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_symbol</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>1_day_change_rate</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TTWO</td>\n",
       "      <td>Take-Two Interactive Software (TTWO) Q4 2024 E...</td>\n",
       "      <td>2024-05-16</td>\n",
       "      <td>p.m. ET\\n\\nOperator\\n\\nGreetings and welcome ...</td>\n",
       "      <td>0.012048</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMAT</td>\n",
       "      <td>Applied Materials (AMAT) Q2 2024 Earnings Call...</td>\n",
       "      <td>2024-05-16</td>\n",
       "      <td>perator\\n\\nWelcome to the Applied Materials ea...</td>\n",
       "      <td>-0.009111</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DXC</td>\n",
       "      <td>DXC Technology (DXC) Q4 2024 Earnings Call Tra...</td>\n",
       "      <td>2024-05-16</td>\n",
       "      <td>ator\\n\\nHello, and welcome to the DXC Technolo...</td>\n",
       "      <td>-0.169014</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LSPD</td>\n",
       "      <td>Lightspeed Commerce (LSPD) Q4 2024 Earnings Ca...</td>\n",
       "      <td>2024-05-16</td>\n",
       "      <td>Operator\\n\\nThank you for standing by, and wel...</td>\n",
       "      <td>0.021192</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JD</td>\n",
       "      <td>JD.com (JD) Q1 2024 Earnings Call Transcript</td>\n",
       "      <td>2024-05-16</td>\n",
       "      <td>, and thank you for standing by for JD.com's f...</td>\n",
       "      <td>0.029180</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>PYCR</td>\n",
       "      <td>Paycor HCM (PYCR) Q1 2024 Earnings Call Transc...</td>\n",
       "      <td>2023-11-08</td>\n",
       "      <td>r\\n\\nLadies and gentlemen, thank you for stand...</td>\n",
       "      <td>0.044258</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>DUOL</td>\n",
       "      <td>Duolingo (DUOL) Q3 2023 Earnings Call Transcript</td>\n",
       "      <td>2023-11-08</td>\n",
       "      <td>van\\n\\nGood evening, everyone. If you haven't ...</td>\n",
       "      <td>0.213726</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>AFRM</td>\n",
       "      <td>Affirm (AFRM) Q1 2024 Earnings Call Transcript</td>\n",
       "      <td>2023-11-08</td>\n",
       "      <td>d afternoon, ladies and gentlemen. Thank you f...</td>\n",
       "      <td>0.142463</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>CART</td>\n",
       "      <td>Instacart (CART) Q3 2023 Earnings Call Transcript</td>\n",
       "      <td>2023-11-08</td>\n",
       "      <td>Good day and thank you for standing by. Welcom...</td>\n",
       "      <td>-0.101322</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>TTWO</td>\n",
       "      <td>Take-Two Interactive Software (TTWO) Q2 2024 E...</td>\n",
       "      <td>2023-11-08</td>\n",
       "      <td>p.m. ET\\n\\nOperator\\n\\nGreetings, and welcome...</td>\n",
       "      <td>0.019865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>985 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    stock_symbol                                              title  \\\n",
       "0           TTWO  Take-Two Interactive Software (TTWO) Q4 2024 E...   \n",
       "1           AMAT  Applied Materials (AMAT) Q2 2024 Earnings Call...   \n",
       "2            DXC  DXC Technology (DXC) Q4 2024 Earnings Call Tra...   \n",
       "3           LSPD  Lightspeed Commerce (LSPD) Q4 2024 Earnings Ca...   \n",
       "4             JD       JD.com (JD) Q1 2024 Earnings Call Transcript   \n",
       "..           ...                                                ...   \n",
       "980         PYCR  Paycor HCM (PYCR) Q1 2024 Earnings Call Transc...   \n",
       "981         DUOL   Duolingo (DUOL) Q3 2023 Earnings Call Transcript   \n",
       "982         AFRM     Affirm (AFRM) Q1 2024 Earnings Call Transcript   \n",
       "983         CART  Instacart (CART) Q3 2023 Earnings Call Transcript   \n",
       "984         TTWO  Take-Two Interactive Software (TTWO) Q2 2024 E...   \n",
       "\n",
       "           date                                         paragraphs  \\\n",
       "0    2024-05-16   p.m. ET\\n\\nOperator\\n\\nGreetings and welcome ...   \n",
       "1    2024-05-16  perator\\n\\nWelcome to the Applied Materials ea...   \n",
       "2    2024-05-16  ator\\n\\nHello, and welcome to the DXC Technolo...   \n",
       "3    2024-05-16  Operator\\n\\nThank you for standing by, and wel...   \n",
       "4    2024-05-16  , and thank you for standing by for JD.com's f...   \n",
       "..          ...                                                ...   \n",
       "980  2023-11-08  r\\n\\nLadies and gentlemen, thank you for stand...   \n",
       "981  2023-11-08  van\\n\\nGood evening, everyone. If you haven't ...   \n",
       "982  2023-11-08  d afternoon, ladies and gentlemen. Thank you f...   \n",
       "983  2023-11-08  Good day and thank you for standing by. Welcom...   \n",
       "984  2023-11-08   p.m. ET\\n\\nOperator\\n\\nGreetings, and welcome...   \n",
       "\n",
       "     1_day_change_rate  label  \n",
       "0             0.012048      1  \n",
       "1            -0.009111     -1  \n",
       "2            -0.169014     -1  \n",
       "3             0.021192      1  \n",
       "4             0.029180      1  \n",
       "..                 ...    ...  \n",
       "980           0.044258      1  \n",
       "981           0.213726      1  \n",
       "982           0.142463      1  \n",
       "983          -0.101322     -1  \n",
       "984           0.019865      1  \n",
       "\n",
       "[985 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_df = pd.read_csv('0522_price_volatility_binary_label.csv')\n",
    "binary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f8acf53-44a9-4ace-955b-358d7cefa598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' p.m. ET',\n",
       " 'Operator',\n",
       " 'Greetings and welcome to the Take-Two fourth quarter and fiscal year 2024 earnings call. At this time, all participants are in a listen-only mode. A brief question-and-answer session will follow the formal presentation. [Operator instructions] As a reminder, this conference is being recorded.',\n",
       " 'It is now my pleasure to introduce your host, Nicole Shevins, senior vice president of investor relations and corporate communications. Thank you. You may begin.',\n",
       " 'Nicole Shevins--Senior Vice President of Investor Relations and Corporate Communications',\n",
       " \"Good afternoon. Thank you for joining our conference call to discuss our results for the fourth quarter and fiscal year 2024 ended March 31, 2024. Today's call will be led by Strauss Zelnick, Take-Two's chairman and chief executive officer; Karl Slatoff, our president; and Lainie Goldstein, our chief financial officer. We will be available to answer your questions during the Q&A session following our prepared remarks.\",\n",
       " \"Before we begin, I'd like to remind everyone that statements made during this call that are not historical facts are considered forward-looking statements under federal securities laws. These forward-looking statements are based on the beliefs of our management, as well as assumptions made by and information currently available to us. We have no obligation to update these forward-looking statements. Actual operating results may vary significantly from these forward-looking statements based on a variety of factors.\",\n",
       " '',\n",
       " \"These important factors are described in our filings with the SEC, including the company's most recent annual report on Form 10-K and quarterly report on Form 10-Q, including the risks summarized in the section entitled Risk Factors. I'd also like to note that unless otherwise stated, all numbers we will be discussing today are GAAP and all comparisons are year over year. Additional details regarding our actual results and outlook are contained in our press release, including the items that our management uses internally to adjust our GAAP financial results in order to evaluate our operating performance. Our press release also contains a reconciliation of any non-GAAP financial measure to the most comparable GAAP measure.\",\n",
       " \"In addition, we have posted to our website a slide deck that visually presents our results and financial outlook. Our press release and filings with the SEC may be obtained from our website at take2games.com. And now, I'll turn the call over to Strauss.\",\n",
       " 'Strauss Zelnick--Chairman and Chief Executive Officer',\n",
       " \"Thanks, Nicole. Good afternoon and thank you for joining us today. I'm pleased to report that we concluded fiscal 2024 with strength, including net bookings of $1.35 billion, which exceeded the high end of our guidance range. Contributing to our positive results was the outperformance of NBA 2K24; Zynga's in-app purchases, led by Toon Blast and our newest hit, Match Factory; and the Red Dead Redemption and Grand Theft Auto series.\",\n",
       " \"During fiscal 2024, we generated net bookings of $5.33 billion, driven by our high-quality titles and our ability to engage consistently our player communities. With fiscal 2025 underway, our portfolio is gaining momentum and we have many exciting releases planned for the year. We expect net bookings to be in the range of $5.55 billion to $5.65 billion, representing 5% year-over-year growth. Our outlook reflects a narrowing of Rockstar Games' previously established window of calendar 2025 to fall of calendar 2025 for Grand Theft Auto VI.\",\n",
       " \"We're highly confident that Rockstar Games will deliver an unparalleled entertainment experience, and our expectations for the commercial impact of the title continue to increase. As we release our groundbreaking pipeline, we expect to achieve tremendous growth, including sequential increases in net bookings in fiscal 2025, 2026, and 2027. We've been executing our substantial cost reduction program, which we now anticipate will result in over $165 million of annual cost savings from our current and future expenses. This will enable us to run our business more efficiently and achieve greater operating leverage as our large-scale titles come to market.\",\n",
       " 'Now, turning to our performance during the quarter. NBA 2K24, which remains the No. 1 basketball simulation experience in our industry, surpassed our expectations as players responded to our promotions, in-game content strategy, and updates within seasons. To date, the title has sold-in over 9 million units.',\n",
       " \"Engagement remains high, with nearly 2 million consumers playing daily. Our industry-leading NBA 2K brand also continued to expand its audience through several innovative mobile experiences, including NBA 2K24 MyTEAM, the new free-to-download mobile experience that allows players to sync progress between console and mobile devices as they play their favorite MyTEAM modes on the go; NBA 2K Mobile; and NBA 2K24 Arcade Edition, which is consistently in the top 5 on Apple Arcade. The Grand Theft Auto series delivered another fantastic quarter, partially driven by an array of free content updates for Grand Theft Auto Online, including new vehicles, drag races, holiday-themed items to celebrate Lunar New Year and Valentine's Day, new community series jobs, and more. Unit sales for Grand Theft Auto V exceeded our forecast.\",\n",
       " \"And to date, the title has sold-in approximately 200 million units worldwide. We're thrilled that more than a decade after their initial releases, Grand Theft Auto V and Grand Theft Auto Online grew their audience size by an incredible 35% and 23%, respectively, for the full year. Grand Theft Auto V also reclaimed its top spot as the most watched video game across all platforms, according to Streamhatchet, thanks largely to the tremendous viewership from the series' thriving role-play community. Rockstar's premium subscription service, GTA+, also continues to grow, with membership for the quarter almost doubling over the same period in the prior year as Rockstar continues to add valuable benefits to players.\",\n",
       " \"Red Dead Redemption 2 also surpassed our expectations and has sold-in nearly 64 million units worldwide. We continue to expand the audience for the series with Red Dead Redemption and Undead Nightmare recently added to the roster of games included within the GTA+ library. Borderlands 3 outpaced our forecasts, and we're thrilled that Randy Pitchford and Gearbox Entertainment are slated to join officially 2K's renowned internal studios in the coming weeks. We've already identified many potential growth opportunities for the Borderlands series and Gearbox's catalog, which we plan to pursue once the studio is integrated into our organization.\",\n",
       " \"We're also excited to see growing buzz for the star-studded Borderlands feature film, which is planned for release by Lionsgate this summer. WWE 2K24 has been a resounding success and is the highest-rated sports simulation of 2024. The title is also the highest-rated installment in the history of our popular wrestling franchise on Xbox, with an 83 average Metacritic score. Engagement has been exceptional, with players logging over 11 million hours across more than 110 million played matches.\",\n",
       " \"In addition, the Forty Years of WrestleMania Pack has the highest attach rate for a Super Deluxe DLC in the series' history, with more than 25% of WWE 2K24 players owning it. 2K and Visual Concepts are continuing to support the title and will have additional packs launching throughout the fall. I'd like to thank our friends Nick Kahn and Ari Emanuel over at WWE, TKO, and WME for their continued support. Additionally, I'd like to express our immense gratitude to our team at Visual Concepts for their outstanding work on our WWE 2K and NBA 2K franchises, which are both important annual contributors for our company.\",\n",
       " \"Zynga delivered outstanding results for the period, led by robust in-app purchases. Match Factory is accelerating and proving to be a hit, already establishing itself as a top 20 grossing game in the U.S. Apple App Store and reaching millions of new users with its launch on the Google Play Store. We're pleased that new bold beats and other exciting features have propelled average daily playtime to around 60 minutes per user.\",\n",
       " \"Toon Blast maintained its positive momentum, achieving nearly 20% growth of in-app purchases compared to the third quarter, driven by a new Dragons' Treasure competition and many other features. We'd like to congratulate the team at Peak for their incredible performance. Top Troops launched several content updates, as well as a major cross-media collaboration with the popular influencer MrBeast. The team plans to release additional enhancements to core gameplay and progression systems to drive further growth.\",\n",
       " 'Momentum continues at Rollic, with the studio crossing 3.5 billion all-time downloads and announcing a new partnership with Mattel to introduce a mass-market Barbie mobile game later this calendar year. Our blended monetization efforts in hyper-casual are progressing well within Rollic, which has resulted in Twisted Tangle and Screw Jam both becoming top 100 grossing games on the U.S. Apple App Store. Our direct-to-consumer business continues to grow, and our teams are working actively to add more titles each quarter to this highly accretive, owned distribution channel.',\n",
       " \"Looking ahead, Zynga has numerous titles in development and soft launch that we're eager to release worldwide this fiscal year, including Star Wars Hunters and Game of Thrones: Legends. In closing, I'm highly confident in our business, led by our top creative talent, our industry-leading portfolio of owned intellectual property, our sound balance sheet, and our increasingly efficient infrastructure. Our teams are laser-focused on our core tenets of creativity, innovation, and efficiency. And as we deliver our groundbreaking pipeline over the next several years, we're poised also to deliver industry-leading growth and shareholder returns.\",\n",
       " \"I'll now turn the call over to Karl.\",\n",
       " 'Karl Slatoff--President',\n",
       " \"Thanks, Strauss. I'd like to thank our teams for their dedication and hard work as we continue to build the foundation for our future, which we believe is more promising than ever. We are extremely excited about our upcoming pipeline, which includes approximately 40 titles through fiscal 2027. Our updated release schedule reflects the actions of our recent cost reduction program, through which we canceled several titles to focus our efforts and resources on the franchises we believe represent our best opportunities to achieve significant critical and commercial success.\",\n",
       " \"These titles did not include any of our core franchises and were not expected to materially affect our net bookings growth. Turning to fiscal 2025. We have 16 titles in our pipeline, three of which have already been released. We have seven immersive core titles, including TopSpin, NBA, and, WWE 2K25, and the next iteration in one of 2K's biggest and most beloved franchises, with the first details coming in just a few short weeks at Summer Games Fest Kickoff Live.\",\n",
       " \"Of these titles, TopSpin 2K25 was released by 2K and Hangar 13 on April 26th. The revival of our popular tennis franchise has been well-received by critics and provides deep personalization, iconic venues, and industry-leading gameplay. With TopSpin 2K25, we continue to broaden our sports offerings, and 2K will support the title with season packs throughout the year. We have two independent titles from Private Division, the first of which is Moon Studio's No Rest for the Wicked, which launched on April 18th into Early Access on PC.\",\n",
       " 'This new ARPG was well-received for its visceral combat, distinct art style, and rich narrative. Private Division, along with Weta Workshop, also announced Tales of the Shire: A Lord of the Rings Game, which is planned for release later this year. The teams recently revealed a new trailer for this cozy, hobbit life sim, which is set in the Middle-earth universe of J.R.R Tolkien. We have five mobile titles, including NFL 2K Playmakers, Star Wars Hunters, and Game of Thrones: Legends.',\n",
       " \"NFL 2K Playmakers was released on April 23rd by 2K and Cat Daddy Games for iOS and Android devices. In this nonsimulation tactical card battle, players can collect NFL player cards to assemble an exciting roster while also experiencing a variety of game modes and features. We're proud to add NFL 2K Playmakers to our ever-growing mobile portfolio in partnership with the NFL and the NFL Players Association. Lastly, we have two new iterations of prior releases planned for this year.\",\n",
       " \"As always, our labels will continue to provide new content and experiences that drive engagement and recurrent consumer spending across many of our key offerings. Looking ahead, our pipeline for fiscal 2026 and 2027 has 24 titles planned, including 15 immersive core releases: six of which are sports simulation games; one independent title; five mobile games; and three new iterations of previously released titles. In closing, we believe that the many opportunities ahead of us will deliver a period of meaningful long-term growth, margin expansion, and shareholder returns. I'll now turn the call over to Lainie.\",\n",
       " 'Lainie Goldstein--Chief Financial Officer',\n",
       " 'Thanks, Karl, and good afternoon, everyone. We delivered a strong finish to fiscal 2024 and are entering fiscal 2025 with momentum, including healthy trends across our key franchises. Throughout the year, we released successful hit titles, engaged players with a steady cadence of in-game content, and continued to position our organization for the long term. We also deepened our commitment to efficiency and made some decisions that, while difficult, will align our resources with the initiatives for which we have the highest levels of conviction.',\n",
       " \"We are confident that, over time, these steps will drive our scale, enhance our margins, and deliver industry-leading returns for our shareholders. I'd like to thank our teams for their vision, passion, and dedication. Turning to our results. We delivered fourth quarter net bookings of $1.35 billion, which was above our guidance range of $1.27 billion to $1.32 billion.\",\n",
       " \"This reflected better-than-expected results from NBA 2K24; Zynga's in-app purchases, led by Toon Blast and Match Factory; the Red Dead Redemption series; and the Grand Theft Auto series. Recurrent consumer spending declined 2% for the period and accounted for 79% of net bookings. This was above our outlook, driven by the outperformance of NBA 2K2, Toon Blast, and Match Factory. Recurrent consumer spending declined for Grand Theft Auto Online, although it was up for virtual currency and GTA+.\",\n",
       " \"NBA 2K was in line with the prior year, and mobile increased slightly. During the quarter, we successfully launched WWE 2K24, which demonstrates 2K and Visual Concepts' ability to raise the bar further for our popular wrestling series. GAAP net revenue decreased 3% to $1.4 billion, while cost of revenue declined 24% to $930 million and included an impairment charge of $304 million related to acquired intangible assets. Operating expenses increased by 244% to $3.2 billion due to a goodwill impairment charge of $2.2 billion and $93 million of business reorganization expenses related to our recently announced cost reduction program.\",\n",
       " 'On a management basis, operating expenses rose 20% year over year, which was slightly above our guidance, due to higher personnel and IT expenses and professional fees. For fiscal 2024, we achieved net bookings of $5.33 billion, which was slightly above our revised guidance range of $5.25 billion to $5.3 billion. Recurrent consumer spending grew 2%, which exceeded our outlook and accounted for 78% of net bookings. Recurrent consumer spending for mobile increased high single-digits; NBA 2K virtual currency and seasons was up slightly; and Grand Theft Auto Online virtual currency and GTA+ membership was flat.',\n",
       " 'Non-GAAP adjusted unrestricted operating cash flow was $42 million, as compared to our outlook of approximately $100 million, due to higher external developer advances, cash tax, and interest payments. We spent approximately $142 million on capital expenditures, primarily for game technology and office build-outs. GAAP net revenue was flat at $5.35 billion, and cost of revenue increased 1% to $3.1 billion, which included an impairment charge of $577 million related to acquired intangible assets. Operating expenses increased 69% to $5.8 billion, due to an impairment charge of $2.3 billion related to goodwill and $105 million business reorganization charge related to our cost reduction programs.',\n",
       " 'On a management basis, operating expenses rose 15% year over year and were slightly above our guidance, due to the factors I mentioned earlier that affected the fourth quarter. Today, we provided our outlook for fiscal 2025. We project net bookings to range from $5.55 billion to $5.65 billion, which represents 5% growth over fiscal 2024. The largest contributors to net bookings are expected to be NBA 2K, the Grand Theft Auto series, Toon Blast, Empires & Puzzles, our hyper-casual mobile portfolio, Match Factory, the Red Dead Redemption series, an unannounced immersive core title from 2K, and Words With Friends.',\n",
       " 'We expect recurrent consumer spending to be up approximately 3% compared to fiscal 2024 and to represent 76% of net bookings. Our recurrent consumer spending forecast assumes high single-digit growth for mobile, a slight increase for NBA 2K, and a decline for Grand Theft Auto Online. We expect the net bookings breakdown from our labels to be roughly 50% Zynga, 31% 2K, 17% Rockstar Games, and 2% other. And we forecast our geographic net bookings split to be about 60% United States and 40% international.',\n",
       " 'We expect non-GAAP adjusted unrestricted operating cash flow to be an outflow of $200 million, and we plan to deploy approximately $140 million for capital expenditures, primarily for game technology and office build-outs. We expect GAAP net revenue to range from $5.57 billion to $5.67 billion and cost of revenue to range from $2.43 billion to $2.46 billion. Turning to operating expenses. We recently implemented a cost reduction program that is expected to deliver over $165 million of annual cost savings across our entire business.',\n",
       " 'As part of these efforts, we have eliminated several projects in development that we did not anticipate would meet our financial benchmarks. We also took actions to streamline our organizational structure, which reduced both existing headcount and future hiring needs. Our total operating expenses are expected to range from $3.56 billion to $3.58 billion, as compared to $5.83 billion last year. On a management basis, we expect operating expense growth of approximately 7% year over year, which is largely due to an increase in ongoing marketing support for Match Factory, as well as other mobile and immersive core launches planned for the year, partially offset by savings from our cost reduction program.',\n",
       " 'Looking ahead and as Strauss mentioned earlier, we have narrowed the previously established release window for Grand Theft Auto VI to fall of calendar 2025 from calendar 2025. As development advances, our confidence in the title and its potential commercial impact continue to grow. That said, we are not providing specific guidance beyond fiscal 2025 as our release schedule includes numerous titles each year and even modest shifts can have a significant effect on results in any given period. Our outlook for the lifetime value of our pipeline remains as strong as ever, and we expect sequential growth in net bookings in fiscal 2025, 2026, and 2027.',\n",
       " 'Now, moving on to our guidance for the fiscal first quarter. We project net bookings to range from $1.2 billion to $1.25 billion, compared to $1.2 billion in the first quarter last year. Our release slate for the quarter includes TopSpin 2K25, No Rest for the Wicked on Early Access for PC, and NFL 2K Playmakers, all of which have already released, and Star Wars Hunters. The largest contributors to net bookings are expected to be NBA 2K, the Grand Theft Auto series, Toon Blast, Empires & Puzzles, our hyper-casual mobile portfolio, Match Factory, the Red Dead Redemption series, Words With Friends, and Zynga Poker.',\n",
       " 'We project recurrent consumer spending to increase by approximately 1%, which assumes mid-single-digit growth in mobile, flat results for NBA 2K, and a decline for Grand Theft Auto Online. We expect GAAP net revenue to range from $1.3 billion to $1.35 billion. Operating expenses are planned to range from $928 million to $938 million. On a management basis, operating expenses are expected to grow by approximately 14% year over year, which is primarily driven by additional marketing for Match Factory, partially offset by our cost reduction program.',\n",
       " \"In closing, we believe that we are very well-positioned to deliver the highest quality content in our industry and to enhance our profitability as we grow our scale and maintain our focus on efficiency. We are extremely excited about our path to the future, and we look forward to sharing more details about the many catalysts ahead for our company. Thank you. I'll now turn the call back to Strauss.\",\n",
       " 'Strauss Zelnick--Chairman and Chief Executive Officer',\n",
       " \"Thanks, Lainie and Karl. On behalf of our entire management team, I'd like to thank our colleagues for their dedication to our business and for creating the highest quality, most engaging entertainment franchises that captivate our global audiences. And to our shareholders, I want to express our appreciation for your continued support. We'll now take your questions.\",\n",
       " 'Operator.',\n",
       " 'Operator',\n",
       " 'Thank you. We will now be conducting a question-and-answer session. [Operator instructions] Our first question comes from the line of Eric Handler with ROTH MKM. Please proceed with your question.',\n",
       " 'Eric Handler--ROTH MKM -- Analyst',\n",
       " \"Good afternoon. Thanks for the question. Strauss, I wonder if you could talk a little bit about the Gearbox acquisition. In the past, you've expressed that you never really felt the need to own all of Gearbox.\",\n",
       " \"Here you are about to own all of Gearbox. Can you talk about how you think about now owning all of Gearbox and some of the opportunities that you'll have with that?\",\n",
       " 'Strauss Zelnick--Chairman and Chief Executive Officer',\n",
       " \"Thanks, Eric. What I was referring to is, when asked when Gearbox was sold to Embracer, whether that caused us to have any concern, my response was no because we have a long-term publishing agreement, and that's been mutually beneficial for our company and for Gearbox and as it was for Embracer. However, when the opportunity presented itself for us to acquire the company on terms that we felt were reasonable, we frankly jumped at the opportunity. You know, we have all the respect in the world for Randy Pitchford and his team.\",\n",
       " \"He has the ability to bring AAA products to market responsibly and on a very reliable and rather rapid cadence. And he's a hitmaker. And it's very hard to make a new hit, and Tiny Tina was a new hit. And of course, Borderlands just goes from strength to strength.\",\n",
       " \"So, we're thrilled to have Gearbox in the family.\",\n",
       " 'Eric Handler--ROTH MKM -- Analyst',\n",
       " \"OK. And then, Lainie, with regards to the annual cost savings that you announced, how much of that should be seen in fiscal '25?\",\n",
       " 'Lainie Goldstein--Chief Financial Officer',\n",
       " \"So, we'll start to see it in fiscal '25, but we'll see a full annualization of it in fiscal year '26. So, the majority of the plan was executed in Q4 and Q1, but it's -- pieces of it will come through this year.\",\n",
       " 'Operator',\n",
       " 'And our next question comes from the line of Doug Creutz with TD Cowen. Please proceed with your question.',\n",
       " 'Doug Creutz--Cowen and Company -- Analyst',\n",
       " 'Hey. Thank you. The ability of Rollic to launch top 100 grossing games is a really pleasant surprise. Just wondering if you could talk about how to think about the life cycle of those games.',\n",
       " \"You know, typically, Rollic's games are sort of -- you know, they're hot for a while, and then they move on to something next -- something else. Is this going to be the case for these monetizing games as well or is it -- it planned to have a longer life cycle? Thank you.\",\n",
       " 'Strauss Zelnick--Chairman and Chief Executive Officer',\n",
       " 'Undoubtedly, this so-called hybrid-casual approach should lead to longer life cycles because the hyper-casual approach really was, you know, put it out there, get a bunch of downloads, offer a rather light experience, you know, generate advertising revenue, have the users move on to the next. And that was great while it lasted. But, you know, long-term entertainment businesses are all driven by great content, and Rollic is proving that it has the ability with its partner studios to do just that and to deliver content that is durable and long-lasting. It remains to be seen whether we can truly create forever franchises at Rollic.',\n",
       " \"I believe we can. We haven't done so yet, but we're off to a really good start.\",\n",
       " 'Doug Creutz--Cowen and Company -- Analyst',\n",
       " 'Thank you.',\n",
       " 'Operator',\n",
       " 'And our next question comes from the line of Colin Sebastian with Baird. Please proceed with your question.',\n",
       " 'Colin Sebastian--Robert W. Baird and Company -- Analyst',\n",
       " \"Thanks. Good afternoon. Maybe a couple for me. I guess, first off, on the change to the guidance and the outlook, what is your level of confidence, Strauss, in that calendar '25 launch of GTA VI, and is there any -- anything else more specific you can talk about what's behind that postponement? And then secondly, on the high single-digit mobile growth, I'm curious how much of that is related to any recovery you're seeing broadly in mobile gaming, or is that more specific to the increase in marketing spend and these titles that are outperforming your expectations for this year? Thank you.\",\n",
       " 'Strauss Zelnick--Chairman and Chief Executive Officer',\n",
       " \"Thanks, Colin. Well, we actually narrowed calendar 2025 to fall of 2025, and we feel really good about that release date. And obviously, we feel great about the title that is to come. And with regard to mobile, what we do at Zynga, because we are the market leader, of course, it's driven by the market in which we live.\",\n",
       " \"And it is gratifying that after a down year and then a slightly down year, we're heading into a flatter up year for the industry. Obviously, though, what's driving our expected results would be our hits, including Match Factory, which is performing really, really well. And we said that we were spending a lot in UA in the fourth quarter. We did, and that's turned out to be productive spending.\",\n",
       " 'Colin Sebastian--Robert W. Baird and Company -- Analyst',\n",
       " 'All right. Thank you.',\n",
       " 'Operator',\n",
       " 'Our next question comes from the line of Matthew Coss with Morgan Stanley. Please proceed with your question.',\n",
       " 'Matt Coss--Morgan Stanley -- Analyst',\n",
       " \"Hi, everyone. Thanks for taking the question. I guess between the success you've had with Match Factory and some new launch titles, setting a release date for Star Wars Hunters, and then the incremental marketing behind mobile, it seems like there's definitely more momentum in that business, which is great to see. I guess, when we think about your analytical framework for investing in the marketing behind mobile, what are you targeting from a margin or payback perspective and when should we expect to see this investment turn into profitable flow-through from the mobile side?\",\n",
       " 'Strauss Zelnick--Chairman and Chief Executive Officer',\n",
       " \"So, I hope, like everyone else, we look at these very same metrics, which is cost of acquisition; what kind of retention you expect, which is to say what kind of churn you get; the spending that you have on average; and therefore, the lifetime value. And the longer a payback period you're willing to accept, of course, the more risk you take in those calculations because they're all based on extrapolating from current data and past data, and they can change at any given time. So, I'm not prepared to share sort of, you know, our outside payback period. Suffice it to say, though, that we want to have a great deal of confidence that we're looking at a positive LTV.\",\n",
       " 'Matt Coss--Morgan Stanley -- Analyst',\n",
       " \"Great. Thank you. And when would you expect to see, you know, mobile -- this investment that you're making in mobile flip from a cost center to, you know, driving incremental profit?\",\n",
       " 'Strauss Zelnick--Chairman and Chief Executive Officer',\n",
       " \"So, of course, our mobile division is profitable. I understand what you're asking, though, which is, frankly, just another way of asking the same question you asked before, which I declined to answer. However, I do give you extra credit points for rephrasing it in a way that I might dive into it. However -- so we don't share our exact payback periods.\",\n",
       " \"We do, however, tailor our user acquisition spending so that we expect a meaningfully positive LTV in a period of time such that we have confidence that even if we're wrong, we're not so wrong that we're not making money. I hope that clarifies it a bit.\",\n",
       " 'Matt Coss--Morgan Stanley -- Analyst',\n",
       " 'It does. Thank you.',\n",
       " 'Operator',\n",
       " 'Our next question comes from the line of Drew Crum with Stifel. Please proceed with your question.',\n",
       " 'Drew Crum--Stifel Financial Corp. -- Analyst',\n",
       " 'Hey. Thanks. Hey, guys. Good afternoon.',\n",
       " \"So, could you address your forecast for NBA 2K RCS in fiscal '25 for a slight increase? Is low single-digits growth the new normal for this going forward, or is there something unique in fiscal '25 that's influencing that view? Thanks.\",\n",
       " 'Karl Slatoff--President',\n",
       " \"So, we absolutely expect growth in NBA, and that's not just on the RCS side but also on the full-game sales side as well. This year is a little bit more challenging because we are still in the transition from Gen 8 to Gen 9, and Gen 9 is outperforming our expectations and doing fantastically well. I'd say we're a little bit more challenged on the Gen 8 side. As we continue to transition, I think we're going to see more tailwinds than headwinds in that regard.\",\n",
       " \"And when you look at the recurrent consumer spending, specifically -- when you look at it specifically as it relates to Gen 9, it's off the charts, it's fantastic. So, we've seen significant growth there. So, again, I think we will have momentum. Just as we transition to Gen 9 and as people continue to engage more deeply in the game, we're going to continue to see very strong RCS growth.\",\n",
       " 'Operator',\n",
       " 'Our next question comes from the line of Benjamin Soff with Deutsche Bank. Please proceed with your question.',\n",
       " 'Benjamin Soff--Deutsche Bank -- Analyst',\n",
       " \"Hey, guys. Thanks for the question. I was wondering if you guys could talk a little bit more about the change in bookings this year versus what you guys were talking about last quarter, how much comes from moving GTA versus any other shifts versus the restructuring. And then -- yeah, I guess I'll stop there.\",\n",
       " 'Thanks.',\n",
       " 'Lainie Goldstein--Chief Financial Officer',\n",
       " \"So, for fiscal year '25, the outlook reflects a narrowing of Rockstar Games' previously established window from the calendar 2025 to fall, as we mentioned. There were also some other movements within the release schedule and also with our cost-cutting plan that is also part of the overall results for that year.\",\n",
       " 'Benjamin Soff--Deutsche Bank -- Analyst',\n",
       " \"Got it. And then a housekeeping question, does your current outlook reflects the acquisition of Gearbox, or is that going to be updated next quarter after it's closed?\",\n",
       " 'Lainie Goldstein--Chief Financial Officer',\n",
       " \"No, it's not included since the transaction hasn't closed yet. So, we will expect to include it next quarter when we close, and we expect it to be slightly accretive to our management results.\",\n",
       " 'Benjamin Soff--Deutsche Bank -- Analyst',\n",
       " \"OK. That's helpful. Thanks, guys.\",\n",
       " 'Operator',\n",
       " 'Our next question comes from the line of Martin Yang with Oppenheimer. Please proceed with your question.',\n",
       " 'Martin Yang--Oppenheimer and Company -- Analyst',\n",
       " 'Hi. Thank you for taking my question. First question, on GTA VI, with the narrowed window of release, is there any associated changes to your plan regarding the live service portion of GTA VI?',\n",
       " 'Strauss Zelnick--Chairman and Chief Executive Officer',\n",
       " \"So, Rockstar hasn't given any details on what its expectations are for the release. It's been a wonderful trailer that they put out that broke the internet. And more news will come from Rockstar in the fullness of time.\",\n",
       " 'Martin Yang--Oppenheimer and Company -- Analyst',\n",
       " \"Thank you. I have a second question, on NBA, how is NBA's transition challenges in between console generations compared to other annually releasing titles on the market, either from 2K or from, you know, other external competitors? And do you attribute the challenges to -- mostly to 2K or to market?\",\n",
       " 'Karl Slatoff--President',\n",
       " \"I'm sorry, was your question about the transition from console generation from the last transition to this transition?\",\n",
       " 'Martin Yang--Oppenheimer and Company -- Analyst',\n",
       " 'Right.',\n",
       " 'Karl Slatoff--President',\n",
       " \"OK. So, that's going back quite some time; and frankly, I don't have the exact figures in front of me. But generally speaking, I would say that the delta between the games in this year, the Gen 9 game and Gen 8 game, is much broader, and I think that creates a more obvious difference between the two games. And frankly, I can't even remember if we had two completely separate games back then.\",\n",
       " 'But in any case, the delta is quite significant this time around, so I would expect that the transition is more -- the effect of the transition is more pronounced in this console generation. And I forget your second question. Was there another one?',\n",
       " 'Martin Yang--Oppenheimer and Company -- Analyst',\n",
       " 'If you do, how does it compare to other studios with annually recurring titles?',\n",
       " 'Karl Slatoff--President',\n",
       " \"Yeah. We're not really commenting on our competitors. And most of our other studios, we don't have as much -- because NBA comes out every year, so you're going to see that transition more brightly. We don't have the same effect in most of our other games.\",\n",
       " \"Occasionally, we would, but they wouldn't be comparable games to NBA anyway. And again, like I said, we don't really comment about the -- our competitors and their experiences.\",\n",
       " 'Martin Yang--Oppenheimer and Company -- Analyst',\n",
       " 'Got it. Thanks, Karl.',\n",
       " 'Operator',\n",
       " 'Our next question comes from the line of Mike Hickey with Benchmark. Please proceed with your question.',\n",
       " 'Mike Hickey--The Benchmark Company -- Analyst',\n",
       " 'Hey, Strauss, Karl, Lainie, Nicole. Thanks for taking the questions. Congrats on the quarter. Strauss, in your prepared comments, you mentioned that your expectations for the commercial impact from GTA VI have increased.',\n",
       " \"I'm just curious if you could explain what's driving that up enthusiasm for the game. And then the second question, on your guidance, curious why you're not providing medium term. You've done that before, and it feels like, here, you have at least better visibility on the primary catalyst driving that growth. And then on '27, tying into that question, wondering where your confidence is that you can grow sequentially off '26.\",\n",
       " \"Is that sort of primarily the GTA ecosystem driving that growth in '27 or it's a combination of that and other AAA games that you plan to release? Thanks, guys.\",\n",
       " 'Strauss Zelnick--Chairman and Chief Executive Officer',\n",
       " \"Thanks, Mike, for those questions. I think our confidence continues to increase just because Grand Theft Auto V continues to perform so well. We've now sold-in over 200 million units. Every quarter, we continue to be pleased by the ongoing sales of the full game.\",\n",
       " \"And engagement in the past fiscal year with Grand Theft Auto V was up about 35% and Grand Theft Auto Online was up about 23%, I believe. That's extraordinary growth at this stage of the game, more than 10 years after the initial release. So, I think we feel as though the market's anticipation is at a fever pitch. And of course, expectations are very high everywhere in this boardroom and all around the world for the perfection of what Rockstar typically delivers.\",\n",
       " \"In terms of your question, I think you're asking in your second question, you know, why didn't we provide very specific guidance for our top-line number going forward? And the answer is, generally speaking, we have not done that except when it was necessary to clarify where we felt the company was going. We think, now, we're being very specific about this fiscal year and about the next couple of fiscal years by saying we expect, relating to your third question, sequential growth on top line, and we think that pretty much answers the question. Finally, the second part of your third question, is that driven by the GTA ecosystem? The answer is, certainly, we have expectations for that ecosystem and, again, given that full-game sales continue to be strong for GTA V this many years later. At the same time, we also have a number of other powerful releases coming, about which we're highly optimistic.\",\n",
       " 'And of course, we have current hits in the marketplace. Match Factory is a huge hit and only accelerating.',\n",
       " 'Mike Hickey--The Benchmark Company -- Analyst',\n",
       " 'Thanks. Thanks, Strauss. Good luck, guys.',\n",
       " 'Operator',\n",
       " 'Our next question comes from the line of Eric Sheridan with Goldman Sachs. Please proceed with your question.',\n",
       " 'Eric Sheridan--Goldman Sachs -- Analyst',\n",
       " \"Thanks so much for taking the question. Maybe if I could just ask a big picture one that's two parts. When you come out of the activity you just went through in terms of reevaluating your pipeline and looking at resource allocation across the organization, what were some of the key learnings on right -- the right mix of content is for you guys to meet your hurdle rate going forward and what were some of the key learnings of how much of the resource allocation decisions are now setting the company up on a multiyear view, or do you think they're going to be a continued refinement as you look to marry resources and the IP pipeline in the years ahead? Thanks so much.\",\n",
       " 'Karl Slatoff--President',\n",
       " \"So, in terms of looking at our pipeline, I mean, this is not really new to us. This is a process that we go through -- that we've been going through for at least the last 17 years since I've been here. And -- but what we -- what we're looking for specifically around this, this -- the look that we just took, is that we're looking -- we -- look, we understand in the industry right now that the biggest games are winning, and they're taking more share. And that's obviously a fact that we've noticed and take very seriously.\",\n",
       " \"And we're simply looking for the projects that we think have the highest chance for commercial success and for critical success and going through and combing through those and going through our pipeline and then making the tough choices. It's always difficult to cancel any projects. But in this context, it was something that was necessary and really part of our normalized process. So, we can -- we absolutely expect that that will continue in the future.\",\n",
       " \"This was a pretty tough look and a pretty big look, so I think most of that is behind us. But we will be adding and we will be subtracting over the next few years, and that's part of what we do. And it'll be both with the -- we will continue to invest in new IP as well. That is not off the table for us.\",\n",
       " \"That's very important. That's the lifeblood of the industry. And if you're not investing in new IP, we think it's a big mistake.\",\n",
       " 'Operator',\n",
       " 'Our next question comes from the line of Jason Bazinet with Citi. Please proceed with your question.',\n",
       " 'Jason Bazinet--Citi -- Analyst',\n",
       " \"I just had one question on GTA VI. This narrowing from calendar '25 to the fall of '25, do you think there's an ancillary benefit to that of sort of syncing up with the holiday season, or do you feel like GTA is such a powerful franchise that it really doesn't confer any sort of incremental benefit?\",\n",
       " 'Strauss Zelnick--Chairman and Chief Executive Officer',\n",
       " \"While it probably doesn't matter, I think we'd all rather be in the release window that we're looking at now.\",\n",
       " 'Jason Bazinet--Citi -- Analyst',\n",
       " 'OK. Thank you.',\n",
       " 'Operator',\n",
       " 'Our next question comes from the line of James Heaney with Jefferies. Please proceed with your question.',\n",
       " 'James Heaney--Jefferies -- Analyst',\n",
       " \"Yeah. Thank you for taking the question. What have been some of the unlocks on the mobile side of the business? You did call out the better-than-expected results in Zynga's IP business, but just curious if there's anything you could say specifically on the advertising side of the business. Thank you.\",\n",
       " 'Strauss Zelnick--Chairman and Chief Executive Officer',\n",
       " \"Look, we have two important businesses within mobile, in-app purchases and advertising, and they're both relevant. We took a hit on advertising as we rethought our hyper-casual business and turned it into a blend of hybrid-casual business where there are in-app purchases as well. At the same time, we built up advertising inside mobile by putting advertising units in games that previously did not have them. In any case, advertising should be a meaningful growth area for us in the mobile business.\",\n",
       " \"With regard to in-app purchases, we have the same opportunities and limitations that any other mobile company has, and our ability to grow in-app purchases is driven by our ability to have people download and play hit titles. That's what we're focused on.\",\n",
       " 'James Heaney--Jefferies -- Analyst',\n",
       " 'Thank you.',\n",
       " 'Operator',\n",
       " 'The next question comes from the line of Clay Griffin with MoffettNathanson. Please proceed with your question.',\n",
       " 'Clay Griffin--MoffettNathanson -- Analyst',\n",
       " \"Yes. Good afternoon. Thank you. I'm curious if you guys would talk about the broader PC strategy.\",\n",
       " \"I know that there's just tons and tons of engagement, particularly for GTA on PC. Not all of that gets monetized. I think, in the past, you've described that as, you know, maybe it's a good thing to have that there. You don't necessarily need to monetize all of it.\",\n",
       " \"But there are some interesting products out there, Overwolf and the like. And so, maybe I'm just curious what you guys are seeing or thinking about your opportunity to unlock monetization on PC. Thanks.\",\n",
       " 'Karl Slatoff--President',\n",
       " \"So, we look at the PC platform as we do with any platform, and it all starts with content, first and foremost. And we agree, it's a very powerful platform and we've got some very strong third-party partners, also the ability for us to sell directly to the consumer. So, these are all compelling things for us, and we'll continue to develop and support the PC platform as long as the gamer is there. Wherever the gamer is, that's where we're going to be.\",\n",
       " \"And again, I don't really see us looking at the PC monetization any differently than we would on any other platform. It really is more about game-to-game. You know, what works for certain games, what doesn't work for certain games. And the overarching edict that we live by is over-deliver on content and the monetization will follow.\",\n",
       " 'Clay Griffin--MoffettNathanson -- Analyst',\n",
       " 'Great. Thanks, Karl.',\n",
       " 'Operator',\n",
       " 'And our next question comes from the line of Chris Schoell with UBS. Please proceed with your question.',\n",
       " 'Chris Schoell--UBS -- Analyst',\n",
       " \"Great. Thank you for taking the questions. We saw Rockstar announce a price increase for GTA+. I recognize it's been several years, but can you help us think through the rationale? And as you look ahead to GTA VI, what are your latest thoughts around the pricing dynamics for the franchise or your portfolio, in general, as these games continue to get larger with more robust experiences? Thank you.\",\n",
       " 'Strauss Zelnick--Chairman and Chief Executive Officer',\n",
       " \"Look, there's more content constantly being made available, and, you know, we really aim to deliver great value at any given time. We're so focused on delivering more value than what we charge. And that's sort of the rubric. And any time we establish a price, we want to make sure that it's good news for the consumer, that the experience vastly over-delivers in the context of the cost.\",\n",
       " \"That's the goal.\",\n",
       " 'Chris Schoell--UBS -- Analyst',\n",
       " 'Great. Thank you.',\n",
       " 'Operator',\n",
       " 'And our next question comes from the line of Omar Dessouky with Bank of America. Please proceed with your question.',\n",
       " 'Omar Dessouky--Bank of America Merrill Lynch -- Analyst',\n",
       " \"Yes. Sure. I have two questions, one on mobile and then just one again on the sequential growth. So, is there any more color at all you can give us on how you're going to grow sequentially in fiscal '27 after lapping just such a tough comp in fiscal '26 when GTA VI is going to launch? It just seems counterintuitive.\",\n",
       " \"When I look back at the last two times Rockstar released a mega title, you know, Red Dead Redemption in fiscal '19, fiscal 20 did not grow; and Grand Theft Auto V in fiscal '14, fiscal 15 was down 30%. I'm just kind of trying to square those couple of things there. You know, will it be Rockstar that continues to drive that sequential growth in fiscal '27? Any more color there would be really great.\",\n",
       " 'Strauss Zelnick--Chairman and Chief Executive Officer',\n",
       " \"Yeah, that's a fair question. Look, the business has really changed and -- certainly since 2019 and absolutely since 2015 and in ways that are obvious now and in ways that we project in the future. This sequential growth is driven by our overall pipeline, and we're now a large and diversified company. And we do have GTA VI coming.\",\n",
       " \"We have great aspirations for GTA VI. And as I said earlier, we've been selling full-game GTA Vs for over 10 years, and we continue to sell more in a given year than most other stand-alone releases sell in their first year, even at our big competitors' companies. So, we actually think that there's a compelling case that the full-game sales will continue to be robust for years to come. Equally, we have a pipeline, both announced and unannounced, that's very exciting.\",\n",
       " \"We have an annualized pipeline that will, of course, continue to come that's quite significant. And we have a mobile business that, you know, we frankly feel has been right-sized, well-structured, and is now back in growth mode. And there's evidence of that. You know, the performance of Match Factory, the performance of Toon Blast, and the stable performance of many other big titles.\",\n",
       " \"There are also geographical growth opportunities that we're very focused on. We don't spend a lot of time talking about it, but it's a huge part of our strategy. You know, the -- our business and our competitors' businesses remain largely U.S.- and Western Europe-focused, and we think there are enormous opportunities for growth in Asia, India, and Africa, where we and everyone else who isn't located in those geographies are deeply under-penetrated. So, there are numerous, numerous opportunities for growth.\",\n",
       " \"But to put your mind at ease, this isn't a, you know, stick a finger in your mouth and hold it in the air and hope for the best kind of number. You know, this is driven by our release schedule and our pipeline.\",\n",
       " 'Omar Dessouky--Bank of America Merrill Lynch -- Analyst',\n",
       " 'OK. And along kind of the same lines, I think a lot of people are going to be super excited about GTA VI coming out. Do you make any assumptions about the perhaps reacceleration of growth in the console installed base or console sales, you know, because your title may, you know, bring a lot of lapsed gamers back into the ecosystem in your forecasts?',\n",
       " 'Strauss Zelnick--Chairman and Chief Executive Officer',\n",
       " \"Yeah, we're using IDG's projections, which are pretty substantial. So, for Gen 9 alone, their view is that there are about 81 million consoles worldwide currently. That was at the end of the last year. They project that will rise to 111 million by the end of this year and 175 million by the end of 2027.\",\n",
       " \"Now, you know, we don't necessarily subscribe or not subscribe to those views, but that shows an awful lot of growth. And we do expect a very significant attach rate.\",\n",
       " 'Omar Dessouky--Bank of America Merrill Lynch -- Analyst',\n",
       " 'Thanks a lot. I appreciate it.',\n",
       " 'Operator',\n",
       " 'Thank you. We have reached the end of our question-and-answer session. And with that, I would like to turn the floor back over to CEO, Strauss Zelnick, for any closing comments.',\n",
       " 'Strauss Zelnick--Chairman and Chief Executive Officer',\n",
       " \"Before we sign off, I just want to thank everyone who works at Take-Two and all of our affiliates. These have been challenging times. And in addition to delivering hits, we've asked everyone to dig deep and make sure the business is highly efficient, right-sized, and that's challenging. And one of the most extraordinary things about our organization is the amazing morale and focus on the common good.\",\n",
       " \"We're here for our customers, for our -- first and foremost, for our colleagues who deliver to our customers every day, and for our shareholders. And we're extraordinarily excited, both about the position we're in, about the fiscal year in which we're currently operating, and about our amazing pipeline and the years ahead. Thank you for joining us today.\",\n",
       " 'Operator',\n",
       " '[Operator signoff]',\n",
       " '']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphs = binary_df['paragraphs'][0].split(\"\\n\\n\")\n",
    "paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9c3a0ce-bf0e-4797-b494-3a3637738ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nicole Shevins--Senior Vice President of Investor Relations and Corporate Communications'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphs[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d924934-a76e-4389-99a1-5bdc7a81120a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8,\n",
       " 8,\n",
       " 293,\n",
       " 161,\n",
       " 88,\n",
       " 421,\n",
       " 519,\n",
       " 0,\n",
       " 731,\n",
       " 253,\n",
       " 53,\n",
       " 434,\n",
       " 543,\n",
       " 658,\n",
       " 309,\n",
       " 827,\n",
       " 717,\n",
       " 646,\n",
       " 496,\n",
       " 619,\n",
       " 428,\n",
       " 514,\n",
       " 576,\n",
       " 645,\n",
       " 36,\n",
       " 23,\n",
       " 576,\n",
       " 467,\n",
       " 537,\n",
       " 487,\n",
       " 484,\n",
       " 615,\n",
       " 41,\n",
       " 550,\n",
       " 371,\n",
       " 496,\n",
       " 637,\n",
       " 614,\n",
       " 702,\n",
       " 618,\n",
       " 507,\n",
       " 537,\n",
       " 709,\n",
       " 653,\n",
       " 619,\n",
       " 552,\n",
       " 400,\n",
       " 53,\n",
       " 368,\n",
       " 9,\n",
       " 8,\n",
       " 196,\n",
       " 33,\n",
       " 209,\n",
       " 164,\n",
       " 53,\n",
       " 531,\n",
       " 263,\n",
       " 49,\n",
       " 33,\n",
       " 128,\n",
       " 41,\n",
       " 211,\n",
       " 8,\n",
       " 106,\n",
       " 41,\n",
       " 190,\n",
       " 271,\n",
       " 53,\n",
       " 636,\n",
       " 79,\n",
       " 41,\n",
       " 10,\n",
       " 8,\n",
       " 107,\n",
       " 55,\n",
       " 594,\n",
       " 53,\n",
       " 320,\n",
       " 395,\n",
       " 55,\n",
       " 21,\n",
       " 8,\n",
       " 109,\n",
       " 36,\n",
       " 581,\n",
       " 53,\n",
       " 669,\n",
       " 36,\n",
       " 182,\n",
       " 53,\n",
       " 353,\n",
       " 253,\n",
       " 36,\n",
       " 19,\n",
       " 8,\n",
       " 98,\n",
       " 44,\n",
       " 39,\n",
       " 235,\n",
       " 23,\n",
       " 463,\n",
       " 390,\n",
       " 8,\n",
       " 109,\n",
       " 39,\n",
       " 309,\n",
       " 7,\n",
       " 41,\n",
       " 312,\n",
       " 39,\n",
       " 167,\n",
       " 41,\n",
       " 192,\n",
       " 39,\n",
       " 33,\n",
       " 8,\n",
       " 105,\n",
       " 47,\n",
       " 192,\n",
       " 53,\n",
       " 219,\n",
       " 47,\n",
       " 300,\n",
       " 23,\n",
       " 118,\n",
       " 47,\n",
       " 6,\n",
       " 23,\n",
       " 393,\n",
       " 248,\n",
       " 47,\n",
       " 79,\n",
       " 23,\n",
       " 255,\n",
       " 176,\n",
       " 47,\n",
       " 21,\n",
       " 8,\n",
       " 103,\n",
       " 45,\n",
       " 220,\n",
       " 428,\n",
       " 160,\n",
       " 53,\n",
       " 263,\n",
       " 466,\n",
       " 906,\n",
       " 106,\n",
       " 45,\n",
       " 41,\n",
       " 8,\n",
       " 109,\n",
       " 39,\n",
       " 671,\n",
       " 23,\n",
       " 524,\n",
       " 457,\n",
       " 304,\n",
       " 128,\n",
       " 8,\n",
       " 100,\n",
       " 30,\n",
       " 300,\n",
       " 53,\n",
       " 109,\n",
       " 30,\n",
       " 14,\n",
       " 8,\n",
       " 104,\n",
       " 34,\n",
       " 301,\n",
       " 53,\n",
       " 500,\n",
       " 255,\n",
       " 34,\n",
       " 10,\n",
       " 8,\n",
       " 111,\n",
       " 41,\n",
       " 97,\n",
       " 265,\n",
       " 202,\n",
       " 23,\n",
       " 453,\n",
       " 334,\n",
       " 41,\n",
       " 20,\n",
       " 8,\n",
       " 103,\n",
       " 29,\n",
       " 399,\n",
       " 53,\n",
       " 387,\n",
       " 16,\n",
       " 29,\n",
       " 17,\n",
       " 8,\n",
       " 115,\n",
       " 55,\n",
       " 317,\n",
       " 401,\n",
       " 53,\n",
       " 332,\n",
       " 470,\n",
       " 386,\n",
       " 511,\n",
       " 210,\n",
       " 55,\n",
       " 351,\n",
       " 53,\n",
       " 304,\n",
       " 166,\n",
       " 55,\n",
       " 30,\n",
       " 8,\n",
       " 177,\n",
       " 53,\n",
       " 403,\n",
       " 356,\n",
       " 8,\n",
       " 18,\n",
       " 0]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_lengths = [len(index) for index in paragraphs]\n",
    "index_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bbf2c89e-5c9f-4fce-81b0-ab9292761415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0, len: 8, Paragraph:  p.m. ET\n",
      "Index: 1, len: 8, Paragraph: Operator\n",
      "Index: 3, len: 161, Paragraph: It is now my pleasure to introduce your host, Nicole Shevins, senior vice president of investor relations and corporate communications. Thank you. You may begin.\n",
      "Index: 4, len: 88, Paragraph: Nicole Shevins--Senior Vice President of Investor Relations and Corporate Communications\n",
      "Index: 7, len: 0, Paragraph: \n",
      "Index: 10, len: 53, Paragraph: Strauss Zelnick--Chairman and Chief Executive Officer\n",
      "Index: 24, len: 36, Paragraph: I'll now turn the call over to Karl.\n",
      "Index: 25, len: 23, Paragraph: Karl Slatoff--President\n",
      "Index: 32, len: 41, Paragraph: Lainie Goldstein--Chief Financial Officer\n",
      "Index: 47, len: 53, Paragraph: Strauss Zelnick--Chairman and Chief Executive Officer\n",
      "Index: 49, len: 9, Paragraph: Operator.\n",
      "Index: 50, len: 8, Paragraph: Operator\n",
      "Index: 51, len: 196, Paragraph: Thank you. We will now be conducting a question-and-answer session. [Operator instructions] Our first question comes from the line of Eric Handler with ROTH MKM. Please proceed with your question.\n",
      "Index: 52, len: 33, Paragraph: Eric Handler--ROTH MKM -- Analyst\n",
      "Index: 54, len: 164, Paragraph: Here you are about to own all of Gearbox. Can you talk about how you think about now owning all of Gearbox and some of the opportunities that you'll have with that?\n",
      "Index: 55, len: 53, Paragraph: Strauss Zelnick--Chairman and Chief Executive Officer\n",
      "Index: 58, len: 49, Paragraph: So, we're thrilled to have Gearbox in the family.\n",
      "Index: 59, len: 33, Paragraph: Eric Handler--ROTH MKM -- Analyst\n",
      "Index: 60, len: 128, Paragraph: OK. And then, Lainie, with regards to the annual cost savings that you announced, how much of that should be seen in fiscal '25?\n",
      "Index: 61, len: 41, Paragraph: Lainie Goldstein--Chief Financial Officer\n",
      "Index: 63, len: 8, Paragraph: Operator\n",
      "Index: 64, len: 106, Paragraph: And our next question comes from the line of Doug Creutz with TD Cowen. Please proceed with your question.\n",
      "Index: 65, len: 41, Paragraph: Doug Creutz--Cowen and Company -- Analyst\n",
      "Index: 66, len: 190, Paragraph: Hey. Thank you. The ability of Rollic to launch top 100 grossing games is a really pleasant surprise. Just wondering if you could talk about how to think about the life cycle of those games.\n",
      "Index: 68, len: 53, Paragraph: Strauss Zelnick--Chairman and Chief Executive Officer\n",
      "Index: 70, len: 79, Paragraph: I believe we can. We haven't done so yet, but we're off to a really good start.\n",
      "Index: 71, len: 41, Paragraph: Doug Creutz--Cowen and Company -- Analyst\n",
      "Index: 72, len: 10, Paragraph: Thank you.\n",
      "Index: 73, len: 8, Paragraph: Operator\n",
      "Index: 74, len: 107, Paragraph: And our next question comes from the line of Colin Sebastian with Baird. Please proceed with your question.\n",
      "Index: 75, len: 55, Paragraph: Colin Sebastian--Robert W. Baird and Company -- Analyst\n",
      "Index: 77, len: 53, Paragraph: Strauss Zelnick--Chairman and Chief Executive Officer\n",
      "Index: 80, len: 55, Paragraph: Colin Sebastian--Robert W. Baird and Company -- Analyst\n",
      "Index: 81, len: 21, Paragraph: All right. Thank you.\n",
      "Index: 82, len: 8, Paragraph: Operator\n",
      "Index: 83, len: 109, Paragraph: Our next question comes from the line of Matthew Coss with Morgan Stanley. Please proceed with your question.\n",
      "Index: 84, len: 36, Paragraph: Matt Coss--Morgan Stanley -- Analyst\n",
      "Index: 86, len: 53, Paragraph: Strauss Zelnick--Chairman and Chief Executive Officer\n",
      "Index: 88, len: 36, Paragraph: Matt Coss--Morgan Stanley -- Analyst\n",
      "Index: 89, len: 182, Paragraph: Great. Thank you. And when would you expect to see, you know, mobile -- this investment that you're making in mobile flip from a cost center to, you know, driving incremental profit?\n",
      "Index: 90, len: 53, Paragraph: Strauss Zelnick--Chairman and Chief Executive Officer\n",
      "Index: 93, len: 36, Paragraph: Matt Coss--Morgan Stanley -- Analyst\n",
      "Index: 94, len: 19, Paragraph: It does. Thank you.\n",
      "Index: 95, len: 8, Paragraph: Operator\n",
      "Index: 96, len: 98, Paragraph: Our next question comes from the line of Drew Crum with Stifel. Please proceed with your question.\n",
      "Index: 97, len: 44, Paragraph: Drew Crum--Stifel Financial Corp. -- Analyst\n",
      "Index: 98, len: 39, Paragraph: Hey. Thanks. Hey, guys. Good afternoon.\n",
      "Index: 100, len: 23, Paragraph: Karl Slatoff--President\n",
      "Index: 103, len: 8, Paragraph: Operator\n",
      "Index: 104, len: 109, Paragraph: Our next question comes from the line of Benjamin Soff with Deutsche Bank. Please proceed with your question.\n",
      "Index: 105, len: 39, Paragraph: Benjamin Soff--Deutsche Bank -- Analyst\n",
      "Index: 107, len: 7, Paragraph: Thanks.\n",
      "Index: 108, len: 41, Paragraph: Lainie Goldstein--Chief Financial Officer\n",
      "Index: 110, len: 39, Paragraph: Benjamin Soff--Deutsche Bank -- Analyst\n",
      "Index: 111, len: 167, Paragraph: Got it. And then a housekeeping question, does your current outlook reflects the acquisition of Gearbox, or is that going to be updated next quarter after it's closed?\n",
      "Index: 112, len: 41, Paragraph: Lainie Goldstein--Chief Financial Officer\n",
      "Index: 113, len: 192, Paragraph: No, it's not included since the transaction hasn't closed yet. So, we will expect to include it next quarter when we close, and we expect it to be slightly accretive to our management results.\n",
      "Index: 114, len: 39, Paragraph: Benjamin Soff--Deutsche Bank -- Analyst\n",
      "Index: 115, len: 33, Paragraph: OK. That's helpful. Thanks, guys.\n",
      "Index: 116, len: 8, Paragraph: Operator\n",
      "Index: 117, len: 105, Paragraph: Our next question comes from the line of Martin Yang with Oppenheimer. Please proceed with your question.\n",
      "Index: 118, len: 47, Paragraph: Martin Yang--Oppenheimer and Company -- Analyst\n",
      "Index: 119, len: 192, Paragraph: Hi. Thank you for taking my question. First question, on GTA VI, with the narrowed window of release, is there any associated changes to your plan regarding the live service portion of GTA VI?\n",
      "Index: 120, len: 53, Paragraph: Strauss Zelnick--Chairman and Chief Executive Officer\n",
      "Index: 122, len: 47, Paragraph: Martin Yang--Oppenheimer and Company -- Analyst\n",
      "Index: 124, len: 23, Paragraph: Karl Slatoff--President\n",
      "Index: 125, len: 118, Paragraph: I'm sorry, was your question about the transition from console generation from the last transition to this transition?\n",
      "Index: 126, len: 47, Paragraph: Martin Yang--Oppenheimer and Company -- Analyst\n",
      "Index: 127, len: 6, Paragraph: Right.\n",
      "Index: 128, len: 23, Paragraph: Karl Slatoff--President\n",
      "Index: 131, len: 47, Paragraph: Martin Yang--Oppenheimer and Company -- Analyst\n",
      "Index: 132, len: 79, Paragraph: If you do, how does it compare to other studios with annually recurring titles?\n",
      "Index: 133, len: 23, Paragraph: Karl Slatoff--President\n",
      "Index: 135, len: 176, Paragraph: Occasionally, we would, but they wouldn't be comparable games to NBA anyway. And again, like I said, we don't really comment about the -- our competitors and their experiences.\n",
      "Index: 136, len: 47, Paragraph: Martin Yang--Oppenheimer and Company -- Analyst\n",
      "Index: 137, len: 21, Paragraph: Got it. Thanks, Karl.\n",
      "Index: 138, len: 8, Paragraph: Operator\n",
      "Index: 139, len: 103, Paragraph: Our next question comes from the line of Mike Hickey with Benchmark. Please proceed with your question.\n",
      "Index: 140, len: 45, Paragraph: Mike Hickey--The Benchmark Company -- Analyst\n",
      "Index: 143, len: 160, Paragraph: Is that sort of primarily the GTA ecosystem driving that growth in '27 or it's a combination of that and other AAA games that you plan to release? Thanks, guys.\n",
      "Index: 144, len: 53, Paragraph: Strauss Zelnick--Chairman and Chief Executive Officer\n",
      "Index: 148, len: 106, Paragraph: And of course, we have current hits in the marketplace. Match Factory is a huge hit and only accelerating.\n",
      "Index: 149, len: 45, Paragraph: Mike Hickey--The Benchmark Company -- Analyst\n",
      "Index: 150, len: 41, Paragraph: Thanks. Thanks, Strauss. Good luck, guys.\n",
      "Index: 151, len: 8, Paragraph: Operator\n",
      "Index: 152, len: 109, Paragraph: Our next question comes from the line of Eric Sheridan with Goldman Sachs. Please proceed with your question.\n",
      "Index: 153, len: 39, Paragraph: Eric Sheridan--Goldman Sachs -- Analyst\n",
      "Index: 155, len: 23, Paragraph: Karl Slatoff--President\n",
      "Index: 159, len: 128, Paragraph: That's very important. That's the lifeblood of the industry. And if you're not investing in new IP, we think it's a big mistake.\n",
      "Index: 160, len: 8, Paragraph: Operator\n",
      "Index: 161, len: 100, Paragraph: Our next question comes from the line of Jason Bazinet with Citi. Please proceed with your question.\n",
      "Index: 162, len: 30, Paragraph: Jason Bazinet--Citi -- Analyst\n",
      "Index: 164, len: 53, Paragraph: Strauss Zelnick--Chairman and Chief Executive Officer\n",
      "Index: 165, len: 109, Paragraph: While it probably doesn't matter, I think we'd all rather be in the release window that we're looking at now.\n",
      "Index: 166, len: 30, Paragraph: Jason Bazinet--Citi -- Analyst\n",
      "Index: 167, len: 14, Paragraph: OK. Thank you.\n",
      "Index: 168, len: 8, Paragraph: Operator\n",
      "Index: 169, len: 104, Paragraph: Our next question comes from the line of James Heaney with Jefferies. Please proceed with your question.\n",
      "Index: 170, len: 34, Paragraph: James Heaney--Jefferies -- Analyst\n",
      "Index: 172, len: 53, Paragraph: Strauss Zelnick--Chairman and Chief Executive Officer\n",
      "Index: 175, len: 34, Paragraph: James Heaney--Jefferies -- Analyst\n",
      "Index: 176, len: 10, Paragraph: Thank you.\n",
      "Index: 177, len: 8, Paragraph: Operator\n",
      "Index: 178, len: 111, Paragraph: The next question comes from the line of Clay Griffin with MoffettNathanson. Please proceed with your question.\n",
      "Index: 179, len: 41, Paragraph: Clay Griffin--MoffettNathanson -- Analyst\n",
      "Index: 180, len: 97, Paragraph: Yes. Good afternoon. Thank you. I'm curious if you guys would talk about the broader PC strategy.\n",
      "Index: 183, len: 23, Paragraph: Karl Slatoff--President\n",
      "Index: 186, len: 41, Paragraph: Clay Griffin--MoffettNathanson -- Analyst\n",
      "Index: 187, len: 20, Paragraph: Great. Thanks, Karl.\n",
      "Index: 188, len: 8, Paragraph: Operator\n",
      "Index: 189, len: 103, Paragraph: And our next question comes from the line of Chris Schoell with UBS. Please proceed with your question.\n",
      "Index: 190, len: 29, Paragraph: Chris Schoell--UBS -- Analyst\n",
      "Index: 192, len: 53, Paragraph: Strauss Zelnick--Chairman and Chief Executive Officer\n",
      "Index: 194, len: 16, Paragraph: That's the goal.\n",
      "Index: 195, len: 29, Paragraph: Chris Schoell--UBS -- Analyst\n",
      "Index: 196, len: 17, Paragraph: Great. Thank you.\n",
      "Index: 197, len: 8, Paragraph: Operator\n",
      "Index: 198, len: 115, Paragraph: And our next question comes from the line of Omar Dessouky with Bank of America. Please proceed with your question.\n",
      "Index: 199, len: 55, Paragraph: Omar Dessouky--Bank of America Merrill Lynch -- Analyst\n",
      "Index: 202, len: 53, Paragraph: Strauss Zelnick--Chairman and Chief Executive Officer\n",
      "Index: 208, len: 55, Paragraph: Omar Dessouky--Bank of America Merrill Lynch -- Analyst\n",
      "Index: 210, len: 53, Paragraph: Strauss Zelnick--Chairman and Chief Executive Officer\n",
      "Index: 212, len: 166, Paragraph: Now, you know, we don't necessarily subscribe or not subscribe to those views, but that shows an awful lot of growth. And we do expect a very significant attach rate.\n",
      "Index: 213, len: 55, Paragraph: Omar Dessouky--Bank of America Merrill Lynch -- Analyst\n",
      "Index: 214, len: 30, Paragraph: Thanks a lot. I appreciate it.\n",
      "Index: 215, len: 8, Paragraph: Operator\n",
      "Index: 216, len: 177, Paragraph: Thank you. We have reached the end of our question-and-answer session. And with that, I would like to turn the floor back over to CEO, Strauss Zelnick, for any closing comments.\n",
      "Index: 217, len: 53, Paragraph: Strauss Zelnick--Chairman and Chief Executive Officer\n",
      "Index: 220, len: 8, Paragraph: Operator\n",
      "Index: 221, len: 18, Paragraph: [Operator signoff]\n",
      "Index: 222, len: 0, Paragraph: \n"
     ]
    }
   ],
   "source": [
    "paragraphs = binary_df['paragraphs'][0].split(\"\\n\\n\")\n",
    "\n",
    "# 找出每個段落長度少於 100 字符的索引\n",
    "short_paragraphs = [index for index, paragraph in enumerate(paragraphs) if len(paragraph) < 200]\n",
    "\n",
    "# 顯示對應索引的段落\n",
    "for index in short_paragraphs:\n",
    "    print(f\"Index: {index}, len: {len(paragraphs[index])}, Paragraph: {paragraphs[index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1846df-96da-4a89-993a-b56abb6df47e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b6eeae-5950-4cb5-a378-fafaa2197b42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b54e63d-5638-41a8-9ca6-2b9c1b85d6ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 計算每個不同字數的索引數量\n",
    "length_count = {}\n",
    "for length in index_lengths:\n",
    "    if length in length_count:\n",
    "        length_count[length] += 1\n",
    "    else:\n",
    "        length_count[length] = 1\n",
    "\n",
    "# 繪製長度分佈圖表\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(length_count.keys(), length_count.values(), color='skyblue')\n",
    "plt.xlabel('Length')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Length Distribution of Index')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aebcf1-47e8-46a8-9acf-60fa6f11c076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "821884be-e078-4e2b-b611-11f1f018832b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['[CLS]', 'ok', '.', 'and', 'along', 'kind', 'of', 'the', 'same', 'lines', ',', 'i', 'think', 'a', 'lot', 'of', 'people', 'are', 'going', 'to', 'be', 'super', 'excited', 'about', 'gt', '##a', 'vi', 'coming', 'out', '.', 'do', 'you', 'make', 'any', 'assumptions', 'about', 'the', 'perhaps', 're', '##ac', '##cel', '##eration', 'of', 'growth', 'in', 'the', 'console', 'installed', 'base', 'or', 'console', 'sales', ',', 'you', 'know', ',', 'because', 'your', 'title', 'may', ',', 'you', 'know', ',', 'bring', 'a', 'lot', 'of', 'laps', '##ed', 'gamer', '##s', 'back', 'into', 'the', 'ecosystem', 'in', 'your', 'forecast', '##s', '?', '[SEP]']\n",
      "Embeddings: tensor([[ 0.1081, -0.4911,  0.0117,  ..., -0.3023,  0.6536,  0.6259],\n",
      "        [ 1.1690, -0.0619,  0.0131,  ...,  0.0337,  1.2560, -0.0471],\n",
      "        [-0.0501, -0.8326,  0.0585,  ...,  0.5313,  0.9838,  0.2298],\n",
      "        ...,\n",
      "        [ 0.5051,  0.1518,  0.2407,  ..., -0.6937,  0.5022,  0.0826],\n",
      "        [-0.4350, -0.8027, -0.8459,  ..., -0.1564,  0.5726,  0.3297],\n",
      "        [ 0.3725,  0.3762,  0.0098,  ...,  0.1866, -0.1704, -0.2156]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# 範例文字\n",
    "text = \"OK. And along kind of the same lines, I think a lot of people are going to be super excited about GTA VI coming out. Do you make any assumptions about the perhaps reacceleration of growth in the console installed base or console sales, you know, because your title may, you know, bring a lot of lapsed gamers back into the ecosystem in your forecasts?\"\n",
    "\n",
    "# 載入預訓練的 BERT 模型與 tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenization\n",
    "inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "\n",
    "# 列出 token 的值\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "print(\"Tokens:\", tokens)\n",
    "\n",
    "# 將文字轉換為 BERT 的輸入格式\n",
    "input_ids = inputs['input_ids']\n",
    "attention_mask = inputs['attention_mask']\n",
    "\n",
    "# 通過 BERT 模型進行前向傳播以提取特徵\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "# 獲取最後一層的隱狀態\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "# 列出 embedding 的值\n",
    "embeddings = last_hidden_states[0]\n",
    "print(\"Embeddings:\", embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96df37b6-a6e9-4c67-82d4-6996098e5859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c835d38b-b429-4b0b-abd4-8329be1fca75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb666b4-695b-4a6f-8f12-9de06e477891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af969496-6727-4507-af8b-d83e38710198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2770e82-e9bc-43d9-9b9a-10d0cbf7fb2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c117c8f7-1767-4a0b-b28e-a8f63963bb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.11763233147706523\n",
      "       Actual  Predicted\n",
      "213 -0.024920   0.068373\n",
      "331  0.006703  -0.231148\n",
      "501 -0.019166  -0.455563\n",
      "309  0.015060   0.001834\n",
      "88  -0.068714  -0.118451\n",
      "CPU times: total: 2.25 s\n",
      "Wall time: 4.73 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 讀取數據\n",
    "train_df = df.copy()\n",
    "\n",
    "# 文本預處理函數\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "train_df['paragraphs'] = train_df['paragraphs'].apply(preprocess_text)\n",
    "\n",
    "# 特徵提取 - 使用TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X = vectorizer.fit_transform(train_df['paragraphs'])\n",
    "\n",
    "# 標籤\n",
    "y = train_df['1_day_change_rate']\n",
    "\n",
    "# 拆分訓練和測試數據\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 訓練模型\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 預測\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 評估模型\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "# 查看部分預測結果\n",
    "results = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "print(results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dce51cb-b4c1-4fd8-9d80-0dd57be8df92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61496cef-f9ae-4b7a-9245-4cebc32f8bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 985/985 [02:18<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.41      0.55      0.47        84\n",
      "           1       0.56      0.42      0.48       113\n",
      "\n",
      "    accuracy                           0.48       197\n",
      "   macro avg       0.49      0.49      0.48       197\n",
      "weighted avg       0.50      0.48      0.48       197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 讀取數據\n",
    "bert_df = binary_df.copy()\n",
    "\n",
    "# BERT 模型與 tokenizer 初始化\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 定義特徵提取函數\n",
    "def extract_features(paragraphs):\n",
    "    inputs = tokenizer(paragraphs, return_tensors='pt', truncation=True, padding=True, max_length=512).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # 使用 [CLS] 標記的向量作為句子的表示\n",
    "    features = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "    return features\n",
    "\n",
    "# 提取特徵並顯示進度條\n",
    "features = []\n",
    "for paragraph in tqdm(bert_df['paragraphs'], desc=\"Extracting features\"):\n",
    "    features.append(extract_features(paragraph))\n",
    "\n",
    "bert_df['features'] = features\n",
    "\n",
    "# 構建訓練和測試集\n",
    "X = np.vstack(bert_df['features'].values)\n",
    "y =bert_df['label'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 訓練 SVM 模型\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# 評估模型\n",
    "y_pred = svm.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14ec2b05-7ceb-4f97-ad8e-8825ea64daa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   0%|          | 0/985 [00:00<?, ?it/s]We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      "Extracting features: 100%|██████████| 985/985 [02:46<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.44      0.60      0.51        84\n",
      "           1       0.59      0.43      0.50       113\n",
      "\n",
      "    accuracy                           0.50       197\n",
      "   macro avg       0.51      0.51      0.50       197\n",
      "weighted avg       0.53      0.50      0.50       197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 讀取數據\n",
    "segment_df = binary_df.copy()\n",
    "\n",
    "# BERT 模型與 tokenizer 初始化\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 定義特徵提取函數（分段處理）\n",
    "def extract_features(paragraphs, max_length=512, stride=256):\n",
    "    inputs = tokenizer(paragraphs, return_tensors='pt', truncation=True, padding=True, max_length=max_length).to(device)\n",
    "    input_ids = inputs['input_ids'][0].tolist()\n",
    "    \n",
    "    features = []\n",
    "    for i in range(0, len(input_ids), stride):\n",
    "        chunk_ids = input_ids[i:i+max_length]\n",
    "        if len(chunk_ids) < max_length:\n",
    "            chunk_ids += [tokenizer.pad_token_id] * (max_length - len(chunk_ids))\n",
    "        chunk_inputs = torch.tensor([chunk_ids]).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=chunk_inputs)\n",
    "        chunk_features = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "        features.append(chunk_features)\n",
    "    \n",
    "    return np.mean(features, axis=0)  # 將所有段落的特徵向量取平均\n",
    "\n",
    "# 提取特徵並顯示進度條\n",
    "features = []\n",
    "for paragraph in tqdm(segment_df['paragraphs'], desc=\"Extracting features\"):\n",
    "    features.append(extract_features(paragraph))\n",
    "\n",
    "segment_df['features'] = features\n",
    "\n",
    "# 構建訓練和測試集\n",
    "X = np.vstack(segment_df['features'].values)\n",
    "y = segment_df['label'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 訓練 SVM 模型\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# 評估模型\n",
    "y_pred = svm.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3dfa2b2-2965-442d-bc10-73dfa007a2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-2.7.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (4.40.1)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda3\\envs\\cuda\\lib\\site-packages (from sentence-transformers) (4.66.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in d:\\anaconda3\\envs\\cuda\\lib\\site-packages (from sentence-transformers) (2.3.0+cu118)\n",
      "Requirement already satisfied: numpy in d:\\anaconda3\\envs\\cuda\\lib\\site-packages (from sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in d:\\anaconda3\\envs\\cuda\\lib\\site-packages (from sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: scipy in d:\\anaconda3\\envs\\cuda\\lib\\site-packages (from sentence-transformers) (1.13.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (0.22.2)\n",
      "Requirement already satisfied: Pillow in d:\\anaconda3\\envs\\cuda\\lib\\site-packages (from sentence-transformers) (10.2.0)\n",
      "Requirement already satisfied: filelock in d:\\anaconda3\\envs\\cuda\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\anaconda3\\envs\\cuda\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\anaconda3\\envs\\cuda\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in d:\\anaconda3\\envs\\cuda\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\anaconda3\\envs\\cuda\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\n",
      "Requirement already satisfied: sympy in d:\\anaconda3\\envs\\cuda\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in d:\\anaconda3\\envs\\cuda\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda3\\envs\\cuda\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in d:\\anaconda3\\envs\\cuda\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (2021.4.0)\n",
      "Requirement already satisfied: colorama in d:\\anaconda3\\envs\\cuda\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\anaconda3\\envs\\cuda\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.4.28)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in d:\\anaconda3\\envs\\cuda\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\anaconda3\\envs\\cuda\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\anaconda3\\envs\\cuda\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in d:\\anaconda3\\envs\\cuda\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in d:\\anaconda3\\envs\\cuda\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers) (2021.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda3\\envs\\cuda\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda3\\envs\\cuda\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda3\\envs\\cuda\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda3\\envs\\cuda\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda3\\envs\\cuda\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\anaconda3\\envs\\cuda\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Downloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n",
      "   ---------------------------------------- 0.0/171.5 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 10.2/171.5 kB ? eta -:--:--\n",
      "   ------ -------------------------------- 30.7/171.5 kB 640.0 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/171.5 kB 544.7 kB/s eta 0:00:01\n",
      "   ------------------------ ------------- 112.6/171.5 kB 726.2 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 163.8/171.5 kB 893.0 kB/s eta 0:00:01\n",
      "   -------------------------------------- 171.5/171.5 kB 790.4 kB/s eta 0:00:00\n",
      "Installing collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-2.7.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6763465-c9a3-45d6-bf7d-f2bd5f66335a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bbe1f6-07e1-4b2f-a50a-55d4ca935b98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58c1b8ca-0a07-486b-b462-f1a1310e2f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['this', 'is', 'an', 'example', 'sentence', '.']\n",
      "Token IDs: [2023, 2003, 2019, 2742, 6251, 1012]\n",
      "Model Inputs: {'input_ids': tensor([[ 101, 2023, 2003, 2019, 2742, 6251, 1012,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# 初始化tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# 要轉換的句子\n",
    "sentence = \"This is an example sentence.\"\n",
    "\n",
    "# 將句子轉換為token\n",
    "tokens = tokenizer.tokenize(sentence)\n",
    "print(\"Tokens:\", tokens)\n",
    "\n",
    "# 將token轉換為ID\n",
    "input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(\"Token IDs:\", input_ids)\n",
    "\n",
    "# 將句子轉換為BERT模型輸入格式\n",
    "inputs = tokenizer(sentence, return_tensors='pt')\n",
    "print(\"Model Inputs:\", inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda0fe6b-d9d7-4dff-83f6-b0e1b4c6093c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8cb98c9-3d51-42d9-bab2-85ae7384f980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9c0e7a685ab424c8f44148c81bd7c4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--sentence-transformers--paraphrase-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d395b4db09c4fcba74cb7e17b64bc62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60175e3c8b804122a9a76245eb972ce6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.73k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a35e4be4f12d4982a786f490f432152f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c969a50152f40bc9aeaee713f5fb8d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c6bcf8fa22d4041b63bb77a9c1e9a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd2f3d390fe7469282f49f453ff7a52b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95f8d05d5f3c451b8d38d9b808650d36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0f1a27eaef44eebb3a33f150c083547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c88bda33014f66ab56423b5abb64dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0490326bb3fc42fcad585fdebf2f7ade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 985/985 [00:36<00:00, 26.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.38      0.45      0.42        84\n",
      "           1       0.53      0.46      0.49       113\n",
      "\n",
      "    accuracy                           0.46       197\n",
      "   macro avg       0.46      0.46      0.45       197\n",
      "weighted avg       0.47      0.46      0.46       197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# 讀取數據\n",
    "df = binary_df.copy()\n",
    "\n",
    "# SBERT 模型初始化\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2', device=device)\n",
    "\n",
    "# 定義特徵提取函數\n",
    "def extract_features(paragraphs):\n",
    "    embeddings = model.encode(paragraphs, convert_to_tensor=True, device=device)\n",
    "    return embeddings.cpu().numpy()\n",
    "\n",
    "# 提取特徵並顯示進度條\n",
    "features = []\n",
    "for paragraph in tqdm(df['paragraphs'], desc=\"Extracting features\"):\n",
    "    features.append(extract_features(paragraph))\n",
    "\n",
    "df['features'] = features\n",
    "\n",
    "# 構建訓練和測試集\n",
    "X = np.vstack(df['features'].values)\n",
    "y = df['label'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 訓練 SVM 模型\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# 評估模型\n",
    "y_pred = svm.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc5719b2-b46c-4eeb-a42e-e0d687067b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.17935905e-01,  4.63625714e-02,  7.65781179e-02, -1.47434756e-01,\n",
       "       -8.23440105e-02, -1.20712973e-01,  1.49829537e-02, -7.55880959e-03,\n",
       "        1.52709752e-01,  1.78763181e-01, -1.77251920e-02, -6.85010701e-02,\n",
       "       -3.12080979e-01, -1.65962726e-01, -1.50961086e-01, -1.10633239e-01,\n",
       "       -6.47302717e-03, -2.17021227e-01,  3.98189574e-02,  4.09236401e-02,\n",
       "        2.01332569e-03, -9.08065587e-03,  1.95513606e-01,  2.33160004e-01,\n",
       "       -5.70637248e-02, -3.94896209e-01, -1.89003535e-03,  1.08723536e-01,\n",
       "        5.87853119e-02, -1.24050796e-01,  2.13978633e-01,  1.50670320e-01,\n",
       "        3.73916388e-01, -1.50742661e-02, -1.42881528e-01,  2.94922590e-01,\n",
       "       -5.15036955e-02,  1.31954581e-01, -2.58468091e-01,  1.03780575e-01,\n",
       "        8.78461357e-03, -3.71213973e-01,  7.16768503e-02, -1.52726561e-01,\n",
       "        1.21567562e-01, -3.54906499e-01, -4.36779261e-02,  2.76638642e-02,\n",
       "        6.04522116e-02,  4.55580726e-02, -1.55488491e-01, -4.07216884e-02,\n",
       "       -5.35856821e-02,  2.21077144e-01,  4.29469272e-02,  6.57151416e-02,\n",
       "       -1.35864407e-01,  1.55031621e-01, -1.15488023e-02, -1.04909062e-01,\n",
       "        1.65939555e-02, -2.34581754e-01, -4.63689089e-01,  4.23847318e-01,\n",
       "       -9.74940509e-02, -6.27827197e-02,  7.34109059e-02,  1.90408558e-01,\n",
       "       -2.35166460e-01, -9.70952660e-02, -2.18620032e-01,  4.27479073e-02,\n",
       "       -1.98711485e-01, -1.37155596e-02,  2.01879039e-01,  2.67495930e-01,\n",
       "        1.58758029e-01, -2.45767143e-02,  2.92228192e-01,  7.23093525e-02,\n",
       "        4.50531155e-01, -3.45202655e-01,  1.60043184e-02, -1.01116031e-01,\n",
       "       -1.72996849e-01,  1.25527531e-01,  8.11167154e-03, -2.45118469e-01,\n",
       "        1.94396093e-01, -2.12061584e-01, -2.73173898e-01,  2.92111844e-01,\n",
       "        1.36915520e-01, -1.19478539e-01,  4.25041392e-02,  1.52207538e-01,\n",
       "        2.42206752e-01, -1.99044615e-01, -5.50151914e-02,  2.53463507e-01,\n",
       "        4.47727181e-02,  3.03680062e-01, -1.14302032e-01, -2.02669173e-01,\n",
       "       -3.10630739e-01, -3.84416133e-02,  1.82933390e-01, -1.55969430e-02,\n",
       "       -2.89198104e-02,  2.11271241e-01, -1.52785242e-01,  1.59138501e-01,\n",
       "       -1.95980355e-01, -4.03055966e-01,  1.47978812e-01,  2.68790781e-01,\n",
       "        4.05041464e-02, -1.17016807e-01,  6.25211000e-01, -5.92551291e-01,\n",
       "       -1.15597881e-01,  2.33619288e-01, -7.00770691e-02, -1.41511291e-01,\n",
       "       -2.17777371e-01,  3.22699219e-01,  1.15588911e-01,  3.12649250e-01,\n",
       "       -5.07976413e-01,  3.12117934e-01,  8.53311867e-02,  2.72125244e-01,\n",
       "        2.20678896e-01,  2.97444820e-01, -1.64790116e-02, -1.71167269e-01,\n",
       "       -2.15479374e-01, -4.88756627e-01, -9.90325734e-02,  7.57722557e-02,\n",
       "        1.97493404e-01, -4.84060764e-01, -2.45030835e-01, -7.87193328e-03,\n",
       "        1.94878668e-01,  2.76724547e-01, -2.98581719e-02, -4.24991548e-02,\n",
       "        3.80324898e-03, -8.08895454e-02, -3.26295167e-01,  5.70239723e-01,\n",
       "        2.74900675e-01, -5.84907159e-02,  3.17649424e-01,  8.20595995e-02,\n",
       "        3.10949594e-01,  4.68495451e-02,  5.76772764e-02,  1.64357767e-01,\n",
       "        5.71405143e-02, -2.74040699e-01,  3.05759281e-01,  2.38722399e-01,\n",
       "       -1.61306351e-01, -1.31868109e-01,  1.38070315e-01, -5.51316515e-03,\n",
       "       -3.03742737e-01,  1.72744691e-01,  5.35792708e-02, -7.00214133e-03,\n",
       "       -5.36980033e-01,  1.01360939e-02,  4.17825699e-01,  1.43818796e-01,\n",
       "        4.75622803e-01,  2.21857950e-01,  2.30553513e-03,  1.34412274e-01,\n",
       "       -1.11633323e-01, -2.25390773e-02,  3.67061198e-01, -7.17253098e-03,\n",
       "       -1.50300637e-02,  2.38374108e-03,  1.62229016e-02, -4.43211496e-02,\n",
       "       -1.99890971e-01,  3.75857353e-01, -2.42769137e-01, -7.96029344e-03,\n",
       "       -1.34689897e-01,  2.62824714e-01, -1.45252615e-01, -9.89135504e-02,\n",
       "        2.86008298e-01, -7.50317574e-02, -8.80696028e-02,  2.53263861e-01,\n",
       "        6.49893060e-02,  1.24828825e-02,  5.12055233e-02,  2.70949781e-01,\n",
       "        1.65752128e-01,  2.91311424e-02,  2.85879165e-01,  1.06562935e-01,\n",
       "        7.69083053e-02, -2.55595390e-02,  6.35537952e-02,  4.53390516e-02,\n",
       "        3.52823660e-02, -1.27578497e-01, -1.22945756e-01,  2.49827623e-01,\n",
       "        7.92637169e-02, -4.86159278e-03,  1.73423603e-01, -1.70518100e-01,\n",
       "        2.12906510e-01,  4.20363545e-01,  1.99637234e-01, -3.13961565e-01,\n",
       "        2.03930646e-01,  7.75540099e-02, -2.46688291e-01, -3.71036768e-01,\n",
       "        1.24084860e-01, -1.75444797e-01,  3.41122001e-02,  2.82942336e-02,\n",
       "        4.67204034e-01, -2.97122121e-01,  2.88010687e-01,  9.40415561e-02,\n",
       "       -1.26469314e-01,  1.13816239e-01, -3.30281258e-01, -6.28142506e-02,\n",
       "       -1.10217594e-02, -2.62332231e-01, -1.55527964e-01, -2.45150719e-02,\n",
       "       -1.35234043e-01,  3.84990513e-01, -3.97819877e-01,  2.92797200e-03,\n",
       "       -2.64654934e-01,  7.80724064e-02,  2.96790451e-01,  8.17468315e-02,\n",
       "       -5.20282686e-02, -4.14612591e-02, -8.53356197e-02, -3.48150820e-01,\n",
       "       -3.79737496e-01,  4.64357823e-01,  9.98408049e-02,  3.74549210e-01,\n",
       "        3.26420903e-01, -3.20902914e-01,  1.10500924e-01, -1.23496577e-02,\n",
       "        2.09296867e-01, -7.26015717e-02, -1.78490579e-01,  2.10068509e-01,\n",
       "        3.44951674e-02,  2.15463698e-01, -2.05729052e-01, -1.59702808e-01,\n",
       "        1.91684559e-01, -1.36374220e-01, -5.46250582e-01,  8.34356993e-02,\n",
       "        4.22326848e-02, -6.20435737e-02, -1.28704488e-01,  3.37016046e-01,\n",
       "       -2.46210359e-02,  3.68985236e-01,  9.32878256e-02,  1.10770732e-01,\n",
       "       -2.06321970e-01, -3.97373229e-01,  2.14601144e-01, -1.51924834e-01,\n",
       "       -1.57751366e-01, -8.63358676e-02, -4.05137464e-02, -1.98680460e-02,\n",
       "       -8.65568519e-02, -6.68937713e-03,  1.70282453e-01, -5.24864066e-04,\n",
       "       -2.18950063e-01, -1.87414497e-01, -5.33843488e-02, -3.04261185e-02,\n",
       "        1.18377708e-01, -3.74192983e-01, -5.01826927e-02,  8.04928988e-02,\n",
       "       -1.93962440e-01,  3.43463480e-01, -9.14803296e-02,  1.51140615e-01,\n",
       "       -4.58218902e-02,  1.85198933e-02,  5.00636041e-01,  1.60293467e-02,\n",
       "       -1.27354681e-01, -4.25991081e-02,  1.05210066e-01, -5.46503477e-02,\n",
       "        1.54122934e-01,  2.27100134e-01,  2.50307828e-01, -4.78268415e-02,\n",
       "        1.61339808e-03, -1.24250546e-01, -8.58143941e-02, -2.54864901e-01,\n",
       "        1.54697657e-01,  3.10250781e-02, -2.70284981e-01, -6.01210892e-01,\n",
       "       -5.80164045e-02, -1.34906113e-01, -2.22027227e-02, -2.24536415e-02,\n",
       "       -4.76035289e-03, -8.40623900e-02,  2.33340338e-01, -7.72332922e-02,\n",
       "       -4.80738580e-01,  7.83505961e-02, -3.12448144e-01, -1.90778255e-01,\n",
       "       -6.82961643e-02, -2.26862058e-02, -1.91791896e-02, -2.15633530e-02,\n",
       "       -1.40416145e-01,  7.31534883e-02,  1.10595405e-01,  1.49746254e-01,\n",
       "       -4.82823029e-02, -6.68307245e-02,  6.88689277e-02,  3.31930935e-01,\n",
       "       -3.13465595e-01, -6.77909842e-03, -1.55879736e-01, -7.80600160e-02,\n",
       "        1.79927424e-02, -1.27213299e-01, -1.27694055e-01, -2.39222310e-03,\n",
       "       -1.12041079e-01,  9.40605626e-02, -4.36885655e-02,  4.55375910e-01,\n",
       "        1.56084448e-01,  2.05000520e-01,  1.21182092e-01,  1.13902008e-02,\n",
       "        1.02356762e-01, -2.96971083e-01, -5.43786138e-02, -1.83158368e-01,\n",
       "        3.25418770e-01,  1.11671872e-01, -2.37773862e-02, -1.32813513e-01,\n",
       "       -4.32442725e-02,  2.50481516e-01,  7.36502632e-02, -2.30273344e-02,\n",
       "       -2.35734984e-01, -1.21374458e-01, -2.73404986e-01,  5.47225177e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['features'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40ad3d06-4701-4ccd-bfdd-584a653510df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BigBirdTokenizer, BigBirdForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import EvalPrediction\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "483add94-5ece-4009-b40d-3f747050d67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in the dataset: [1 0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3ffe91e5cef45d6bac8346eeeffff2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--google--bigbird-roberta-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96b6671cc0044fe1affaaa2cd43f46e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/846k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c956615237e94c49947de371d4fee93d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/775 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38a0089c9c9440a68ef9c8d62ffdba1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/760 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11ad636ae4c44eb4887992e265a4e908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/513M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 68.00 MiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 101\u001b[0m\n\u001b[0;32m     92\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     93\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     94\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     97\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics\n\u001b[0;32m     98\u001b[0m )\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# 開始訓練\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# 保存模型\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# model.save_pretrained('./saved_model')\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m# tokenizer.save_pretrained('./saved_model')\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# 評估模型準確率\u001b[39;00m\n\u001b[0;32m    108\u001b[0m metrics \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\trainer.py:1859\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1857\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1858\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1860\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   1861\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[0;32m   1862\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[0;32m   1863\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[0;32m   1864\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\trainer.py:2203\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m   2202\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m-> 2203\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[0;32m   2205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2206\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2207\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2208\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2209\u001b[0m ):\n\u001b[0;32m   2210\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2211\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\trainer.py:3138\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   3135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   3137\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 3138\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(model, inputs)\n\u001b[0;32m   3140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3141\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\trainer.py:3161\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[0;32m   3159\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3160\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 3161\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m   3162\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[0;32m   3163\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[0;32m   3164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\cuda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\cuda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\big_bird\\modeling_big_bird.py:2742\u001b[0m, in \u001b[0;36mBigBirdForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   2697\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2698\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   2699\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2738\u001b[0m \u001b[38;5;124;03m```\u001b[39;00m\n\u001b[0;32m   2739\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2740\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 2742\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbert(\n\u001b[0;32m   2743\u001b[0m     input_ids,\n\u001b[0;32m   2744\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   2745\u001b[0m     token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids,\n\u001b[0;32m   2746\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   2747\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m   2748\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[0;32m   2749\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   2750\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   2751\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   2752\u001b[0m )\n\u001b[0;32m   2754\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   2755\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\cuda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\cuda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\big_bird\\modeling_big_bird.py:2130\u001b[0m, in \u001b[0;36mBigBirdModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   2120\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m   2122\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[0;32m   2123\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   2124\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2127\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[0;32m   2128\u001b[0m )\n\u001b[1;32m-> 2130\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[0;32m   2131\u001b[0m     embedding_output,\n\u001b[0;32m   2132\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[0;32m   2133\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m   2134\u001b[0m     encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[0;32m   2135\u001b[0m     encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_extended_attention_mask,\n\u001b[0;32m   2136\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m   2137\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m   2138\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   2139\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   2140\u001b[0m     band_mask\u001b[38;5;241m=\u001b[39mband_mask,\n\u001b[0;32m   2141\u001b[0m     from_mask\u001b[38;5;241m=\u001b[39mfrom_mask,\n\u001b[0;32m   2142\u001b[0m     to_mask\u001b[38;5;241m=\u001b[39mto_mask,\n\u001b[0;32m   2143\u001b[0m     blocked_encoder_mask\u001b[38;5;241m=\u001b[39mblocked_encoder_mask,\n\u001b[0;32m   2144\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   2145\u001b[0m )\n\u001b[0;32m   2146\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   2148\u001b[0m pooler_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output[:, \u001b[38;5;241m0\u001b[39m, :])) \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\cuda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\cuda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\big_bird\\modeling_big_bird.py:1628\u001b[0m, in \u001b[0;36mBigBirdEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, band_mask, from_mask, to_mask, blocked_encoder_mask, return_dict)\u001b[0m\n\u001b[0;32m   1613\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m   1614\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m   1615\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1625\u001b[0m         output_attentions,\n\u001b[0;32m   1626\u001b[0m     )\n\u001b[0;32m   1627\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1628\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m layer_module(\n\u001b[0;32m   1629\u001b[0m         hidden_states,\n\u001b[0;32m   1630\u001b[0m         attention_mask,\n\u001b[0;32m   1631\u001b[0m         layer_head_mask,\n\u001b[0;32m   1632\u001b[0m         encoder_hidden_states,\n\u001b[0;32m   1633\u001b[0m         encoder_attention_mask,\n\u001b[0;32m   1634\u001b[0m         band_mask,\n\u001b[0;32m   1635\u001b[0m         from_mask,\n\u001b[0;32m   1636\u001b[0m         to_mask,\n\u001b[0;32m   1637\u001b[0m         blocked_encoder_mask,\n\u001b[0;32m   1638\u001b[0m         past_key_value,\n\u001b[0;32m   1639\u001b[0m         output_attentions,\n\u001b[0;32m   1640\u001b[0m     )\n\u001b[0;32m   1642\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1643\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\cuda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\cuda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\big_bird\\modeling_big_bird.py:1485\u001b[0m, in \u001b[0;36mBigBirdLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, band_mask, from_mask, to_mask, blocked_encoder_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m   1470\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1471\u001b[0m     hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1482\u001b[0m ):\n\u001b[0;32m   1483\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m   1484\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1485\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(\n\u001b[0;32m   1486\u001b[0m         hidden_states,\n\u001b[0;32m   1487\u001b[0m         attention_mask,\n\u001b[0;32m   1488\u001b[0m         head_mask,\n\u001b[0;32m   1489\u001b[0m         encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[0;32m   1490\u001b[0m         encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_attention_mask,\n\u001b[0;32m   1491\u001b[0m         past_key_value\u001b[38;5;241m=\u001b[39mself_attn_past_key_value,\n\u001b[0;32m   1492\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1493\u001b[0m         band_mask\u001b[38;5;241m=\u001b[39mband_mask,\n\u001b[0;32m   1494\u001b[0m         from_mask\u001b[38;5;241m=\u001b[39mfrom_mask,\n\u001b[0;32m   1495\u001b[0m         to_mask\u001b[38;5;241m=\u001b[39mto_mask,\n\u001b[0;32m   1496\u001b[0m         from_blocked_mask\u001b[38;5;241m=\u001b[39mblocked_encoder_mask,\n\u001b[0;32m   1497\u001b[0m         to_blocked_mask\u001b[38;5;241m=\u001b[39mblocked_encoder_mask,\n\u001b[0;32m   1498\u001b[0m     )\n\u001b[0;32m   1499\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1501\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\cuda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\cuda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\big_bird\\modeling_big_bird.py:1398\u001b[0m, in \u001b[0;36mBigBirdAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions, band_mask, from_mask, to_mask, from_blocked_mask, to_blocked_mask)\u001b[0m\n\u001b[0;32m   1396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m encoder_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1397\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBigBird cannot be used as a decoder when config.attention_type != \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal_full\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1398\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself(\n\u001b[0;32m   1399\u001b[0m         hidden_states, band_mask, from_mask, to_mask, from_blocked_mask, to_blocked_mask, output_attentions\n\u001b[0;32m   1400\u001b[0m     )\n\u001b[0;32m   1402\u001b[0m attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[0;32m   1403\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\cuda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\cuda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\big_bird\\modeling_big_bird.py:469\u001b[0m, in \u001b[0;36mBigBirdBlockSparseAttention.forward\u001b[1;34m(self, hidden_states, band_mask, from_mask, to_mask, from_blocked_mask, to_blocked_mask, output_attentions)\u001b[0m\n\u001b[0;32m    466\u001b[0m key_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey(hidden_states))\n\u001b[0;32m    467\u001b[0m value_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue(hidden_states))\n\u001b[1;32m--> 469\u001b[0m context_layer, attention_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbigbird_block_sparse_attention(\n\u001b[0;32m    470\u001b[0m     query_layer,\n\u001b[0;32m    471\u001b[0m     key_layer,\n\u001b[0;32m    472\u001b[0m     value_layer,\n\u001b[0;32m    473\u001b[0m     band_mask,\n\u001b[0;32m    474\u001b[0m     from_mask,\n\u001b[0;32m    475\u001b[0m     to_mask,\n\u001b[0;32m    476\u001b[0m     from_blocked_mask,\n\u001b[0;32m    477\u001b[0m     to_blocked_mask,\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_attention_heads,\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_random_blocks,\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention_head_size,\n\u001b[0;32m    481\u001b[0m     from_block_size,\n\u001b[0;32m    482\u001b[0m     to_block_size,\n\u001b[0;32m    483\u001b[0m     batch_size,\n\u001b[0;32m    484\u001b[0m     from_seq_length,\n\u001b[0;32m    485\u001b[0m     to_seq_length,\n\u001b[0;32m    486\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed,\n\u001b[0;32m    487\u001b[0m     plan_from_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    488\u001b[0m     plan_num_rand_blocks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    489\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    490\u001b[0m )\n\u001b[0;32m    492\u001b[0m context_layer \u001b[38;5;241m=\u001b[39m context_layer\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(batch_size, from_seq_length, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    494\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (context_layer, attention_probs) \u001b[38;5;28;01mif\u001b[39;00m output_attentions \u001b[38;5;28;01melse\u001b[39;00m (context_layer,)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\big_bird\\modeling_big_bird.py:705\u001b[0m, in \u001b[0;36mBigBirdBlockSparseAttention.bigbird_block_sparse_attention\u001b[1;34m(self, query_layer, key_layer, value_layer, band_mask, from_mask, to_mask, from_blocked_mask, to_blocked_mask, n_heads, n_rand_blocks, attention_head_size, from_block_size, to_block_size, batch_size, from_seq_len, to_seq_len, seed, plan_from_length, plan_num_rand_blocks, output_attentions)\u001b[0m\n\u001b[0;32m    703\u001b[0m inner_band_product \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtorch_bmm_nd_transpose(middle_query_matrix, exp_blocked_key_matrix, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m    704\u001b[0m \u001b[38;5;66;03m#     ==> [bsz, n_heads, from_seq_len//from_block_size-4, from_block_size, 3*to_block_size]\u001b[39;00m\n\u001b[1;32m--> 705\u001b[0m inner_band_product \u001b[38;5;241m=\u001b[39m inner_band_product \u001b[38;5;241m*\u001b[39m rsqrt_d\n\u001b[0;32m    707\u001b[0m \u001b[38;5;66;03m# randn attention scores for q[-2:2]\u001b[39;00m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;66;03m# [bsz, n_heads, from_seq_len//from_block_size-4, from_block_size, -1] x [bsz, n_heads, from_seq_len//from_block_size-4, n_rand_blocks*to_block_size, -1]\u001b[39;00m\n\u001b[0;32m    709\u001b[0m rand_band_product \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtorch_bmm_nd_transpose(middle_query_matrix, gathered_key[:, :, \u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 68.00 MiB. GPU "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BigBirdTokenizer, BigBirdForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import EvalPrediction\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "# 讀取CSV文件\n",
    "bird_df = df.copy()\n",
    "\n",
    "# 將標籤從1和-1轉換為0和1\n",
    "bird_df['label'] = bird_df['label'].map({1: 1, -1: 0})\n",
    "\n",
    "# 檢查標籤範圍\n",
    "print(\"Unique labels in the dataset:\", bird_df['label'].unique())\n",
    "\n",
    "# 分割數據集為訓練集和測試集\n",
    "train_df, test_df = train_test_split(bird_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# 加載Tokenizer和模型\n",
    "tokenizer = BigBirdTokenizer.from_pretrained('google/bigbird-roberta-base')\n",
    "model = BigBirdForSequenceClassification.from_pretrained('google/bigbird-roberta-base', num_labels=2)  # 假設是二分類\n",
    "\n",
    "# 創建自定義Dataset類\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=4096):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            return_token_type_ids=False,\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            padding='max_length'  # 填充到最大長度\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# 創建Dataset對象\n",
    "train_dataset = TextDataset(\n",
    "    texts=train_df['paragraphs'].to_list(),\n",
    "    labels=train_df['label'].to_list(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=4096\n",
    ")\n",
    "\n",
    "test_dataset = TextDataset(\n",
    "    texts=test_df['paragraphs'].to_list(),\n",
    "    labels=test_df['label'].to_list(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=4096\n",
    ")\n",
    "\n",
    "# 定義計算準確率的函數\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    return {\"accuracy\": (preds == p.label_ids).mean()}\n",
    "\n",
    "# 定義訓練參數\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2,  # 調整batch size以適應大長度文本\n",
    "    per_device_eval_batch_size=2,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "# 創建Trainer對象\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# 開始訓練\n",
    "trainer.train()\n",
    "\n",
    "# 保存模型\n",
    "# model.save_pretrained('./saved_model')\n",
    "# tokenizer.save_pretrained('./saved_model')\n",
    "\n",
    "# 評估模型準確率\n",
    "metrics = trainer.evaluate()\n",
    "print(f\"Accuracy: {metrics['eval_accuracy']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacb43ac-1a67-4bfb-a79d-dd424de2b984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae75b85-fe19-4072-84e7-88a93c1caedf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6dbfeb-8bed-43a2-809c-e798e1d91bda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
